{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dAQpYjPVzdsw"
   },
   "source": [
    "# Recommendation Systems Assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GUjvLryBzdsx"
   },
   "source": [
    "### MIE451/1513 UofT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R9dHQTK1zds1"
   },
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xncf3xm1zds2",
    "outputId": "46962f91-e89a-427f-c398-e9d67161e454"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting wget\n",
      "  Downloading https://files.pythonhosted.org/packages/47/6a/62e288da7bcda82b935ff0c6cfe542970f04e29c756b0e147251b2fb251f/wget-3.2.zip\n",
      "Building wheels for collected packages: wget\n",
      "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for wget: filename=wget-3.2-cp36-none-any.whl size=9682 sha256=fad973ecc3dc30e4110a3ae1f5cfc4745d8aec8445689d2c8fc7094f3fb4e306\n",
      "  Stored in directory: /root/.cache/pip/wheels/40/15/30/7d8f7cea2902b4db79e3fea550d7d7b85ecb27ef992b618f3f\n",
      "Successfully built wget\n",
      "Installing collected packages: wget\n",
      "Successfully installed wget-3.2\n"
     ]
    }
   ],
   "source": [
    "# import required libraries\n",
    "!pip install wget\n",
    "import os\n",
    "import os.path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from math import sqrt\n",
    "from heapq import nlargest\n",
    "from tqdm import trange\n",
    "from tqdm import tqdm\n",
    "from scipy import stats\n",
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import wget"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F1ill6yOzds5"
   },
   "source": [
    "## Support functions and variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lNbQGMevzds8",
    "outputId": "0e984553-48f3-4b65-c296-bfad75ba90ec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  ml-100k.zip\n",
      "   creating: ml-100k/\n",
      "  inflating: ml-100k/allbut.pl       \n",
      "  inflating: ml-100k/mku.sh          \n",
      "  inflating: ml-100k/README          \n",
      "  inflating: ml-100k/u.data          \n",
      "  inflating: ml-100k/u.genre         \n",
      "  inflating: ml-100k/u.info          \n",
      "  inflating: ml-100k/u.item          \n",
      "  inflating: ml-100k/u.occupation    \n",
      "  inflating: ml-100k/u.user          \n",
      "  inflating: ml-100k/u1.base         \n",
      "  inflating: ml-100k/u1.test         \n",
      "  inflating: ml-100k/u2.base         \n",
      "  inflating: ml-100k/u2.test         \n",
      "  inflating: ml-100k/u3.base         \n",
      "  inflating: ml-100k/u3.test         \n",
      "  inflating: ml-100k/u4.base         \n",
      "  inflating: ml-100k/u4.test         \n",
      "  inflating: ml-100k/u5.base         \n",
      "  inflating: ml-100k/u5.test         \n",
      "  inflating: ml-100k/ua.base         \n",
      "  inflating: ml-100k/ua.test         \n",
      "  inflating: ml-100k/ub.base         \n",
      "  inflating: ml-100k/ub.test         \n"
     ]
    }
   ],
   "source": [
    "wget.download(\"https://github.com/MIE451-1513-2019/course-datasets/raw/master/ml-100k.zip\")\n",
    "!unzip ml-100k.zip\n",
    "MOVIELENS_DIR = \"ml-100k\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "emOWqsTGzdtB",
    "outputId": "87abbc04-5801-487a-ad8f-441fc7e91a7e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "allbut.pl  u1.base  u2.test  u4.base  u5.test  ub.base\tu.genre  u.occupation\n",
      "mku.sh\t   u1.test  u3.base  u4.test  ua.base  ub.test\tu.info\t u.user\n",
      "README\t   u2.base  u3.test  u5.base  ua.test  u.data\tu.item\n"
     ]
    }
   ],
   "source": [
    "!ls {MOVIELENS_DIR}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "3k0-kPF7zdtE"
   },
   "outputs": [],
   "source": [
    "def getData(folder_path, file_name):\n",
    "    fields = ['userID', 'itemID', 'rating', 'timestamp']\n",
    "    data = pd.read_csv(os.path.join(folder_path, file_name), sep='\\t', names=fields)\n",
    "    return data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "nvqWuW5NzdtI"
   },
   "outputs": [],
   "source": [
    "rating_df = getData(MOVIELENS_DIR, 'u.data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 191
    },
    "id": "5RPCAd--22MQ",
    "outputId": "1d216798-afed-4804-c260-7b4bf1affef3"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userID</th>\n",
       "      <th>itemID</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>196</td>\n",
       "      <td>242</td>\n",
       "      <td>3</td>\n",
       "      <td>881250949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>186</td>\n",
       "      <td>302</td>\n",
       "      <td>3</td>\n",
       "      <td>891717742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>377</td>\n",
       "      <td>1</td>\n",
       "      <td>878887116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>244</td>\n",
       "      <td>51</td>\n",
       "      <td>2</td>\n",
       "      <td>880606923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>166</td>\n",
       "      <td>346</td>\n",
       "      <td>1</td>\n",
       "      <td>886397596</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userID  itemID  rating  timestamp\n",
       "0     196     242       3  881250949\n",
       "1     186     302       3  891717742\n",
       "2      22     377       1  878887116\n",
       "3     244      51       2  880606923\n",
       "4     166     346       1  886397596"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating_df.head() #100000x4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SpmN2NrTzdtK",
    "outputId": "1bb35644-d47d-475e-8367-46aa40cfc8b4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of users: 943\n",
      "Number of items: 1682\n"
     ]
    }
   ],
   "source": [
    "num_users = len(rating_df.userID.unique())\n",
    "num_items = len(rating_df.itemID.unique())\n",
    "print(\"Number of users:\", num_users)\n",
    "print(\"Number of items:\", num_items)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GQg7fW9SzdtO"
   },
   "source": [
    "## Q1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jLVaLm25zdtO"
   },
   "source": [
    "### (a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "FiiG_0QfzdtP"
   },
   "outputs": [],
   "source": [
    "def dataPreprocessor(rating_df, num_users, num_items):\n",
    "    \"\"\"\n",
    "        INPUT: \n",
    "            data: pandas DataFrame. columns=['userID', 'itemID', 'rating' ...]\n",
    "            num_row: int. number of users\n",
    "            num_col: int. number of items\n",
    "            \n",
    "        OUTPUT:\n",
    "            matrix: 2D numpy array. \n",
    "            \n",
    "        NOTE 1: see where something very similar is done in the lab in function 'buildUserItemMatrix'    \n",
    "            \n",
    "        NOTE 2: data can have more columns, but your function should ignore \n",
    "              additional columns.\n",
    "    \"\"\"\n",
    "    ########### your code goes here ###########\n",
    "    matrix = np.zeros((num_users, num_items), dtype=np.int8)\n",
    "    for (index, userID, itemID, rating, timestamp) in rating_df.itertuples():\n",
    "        matrix[userID-1, itemID-1] = rating #userID, itemID start from 1\n",
    "    ###########         end         ###########\n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f6DxbgBmzdtS",
    "outputId": "63bdf01b-3945-4584-eeca-a52eb86109e3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5, 3, 4, ..., 0, 0, 0],\n",
       "       [4, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [5, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 5, 0, ..., 0, 0, 0]], dtype=int8)"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataPreprocessor(rating_df, num_users, num_items)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4b4XZHBczdtU"
   },
   "source": [
    "### (b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "z9AkrRvUzdtV"
   },
   "outputs": [],
   "source": [
    "class BaseLineRecSys(object):\n",
    "    def __init__(self, method, processor=dataPreprocessor):\n",
    "        \"\"\"\n",
    "            method: string. From ['popularity','useraverage']\n",
    "            processor: function name. dataPreprocessor by default\n",
    "        \"\"\"\n",
    "        self.method_name = method\n",
    "        self.method = self._getMethod(self.method_name)\n",
    "        self.processor = processor\n",
    "        self.pred_column_name = self.method_name\n",
    "        \n",
    "    def _getMethod(self, method_name):\n",
    "        \"\"\"\n",
    "            Don't change this\n",
    "        \"\"\"\n",
    "        switcher = {\n",
    "            'popularity': self.popularity,\n",
    "            'useraverage': self.useraverage,\n",
    "        }\n",
    "        \n",
    "        return switcher[method_name]\n",
    "    \n",
    "    @staticmethod\n",
    "    def useraverage(train_matrix, num_users, num_items):\n",
    "        \"\"\"\n",
    "            INPUT:\n",
    "                train_matrix: 2D numpy array.\n",
    "                num_users: int. Number of Users.\n",
    "                num_items: int. Number of Items.\n",
    "            OUTPUT:\n",
    "                predictionMatrix: 2D numpy array.\n",
    "                \n",
    "            NOTE: see where something very similar is done in the lab in function 'predictByUserAverage'    \n",
    "        \"\"\"\n",
    "        \n",
    "        predictionMatrix = np.zeros((num_users, num_items))\n",
    "        ########### your code goes here ###########\n",
    "        # Initialize the predicted rating matrix with zeros\n",
    "        for (user,item), rating in np.ndenumerate(train_matrix): \n",
    "        # Predict rating for every item that wasn't ranked by the user (rating == 0)\n",
    "            if rating == 0:\n",
    "                # select the row for user\n",
    "                # what's the shape of userVector\n",
    "                userVector = train_matrix[user, :]\n",
    "\n",
    "                # Extract the items the user already rated\n",
    "                ratedItems = userVector[userVector.nonzero()] #.nonzero() returns the indices, ratedItems contains only the nonzero values\n",
    "\n",
    "                # If not empty, calculate average and set as rating for the current item\n",
    "                if ratedItems.size == 0:\n",
    "                    itemAvg = 0\n",
    "                else:\n",
    "                    itemAvg = ratedItems.mean()\n",
    "                predictionMatrix[user, item] = itemAvg\n",
    "\n",
    "        ###########         end         ###########\n",
    "        return predictionMatrix\n",
    "    \n",
    "    @staticmethod\n",
    "    def popularity(train_matrix, num_users, num_items):\n",
    "        \"\"\"\n",
    "            INPUT:\n",
    "                train_matrix: 2D numpy array.\n",
    "                num_users: int. Number of Users.\n",
    "                num_items: int. Number of Items.\n",
    "            OUTPUT:\n",
    "                predictionMatrix: 2D numpy array.\n",
    "                \n",
    "            NOTE: see where something very similar is done in the lab in function 'predictByPopularity'    \n",
    "        \"\"\"\n",
    "        \n",
    "        predictionMatrix = np.zeros((num_users, num_items))\n",
    "        ########### your code goes here ###########\n",
    "        # Initialize the predicted rating matrix with zeros\n",
    "        # Define function for converting 1-5 rating to 0/1 (like / don't like)\n",
    "        vf = np.vectorize(lambda x: 1 if x >= 4 else 0)\n",
    "        \n",
    "        # For every item calculate the number of people liked (4-5) divided by the number of people that rated\n",
    "        itemPopularity = np.zeros((num_items))\n",
    "        for item in range(num_items):\n",
    "            numOfUsersRated = len(train_matrix[:, item].nonzero()[0])\n",
    "            numOfUsersLiked = len(vf(train_matrix[:, item]).nonzero()[0])\n",
    "            if numOfUsersRated == 0:\n",
    "                itemPopularity[item] = 0\n",
    "            else:\n",
    "                itemPopularity[item] = numOfUsersLiked/numOfUsersRated\n",
    "        \n",
    "        for (user,item), rating in np.ndenumerate(train_matrix):\n",
    "            # Predict rating for every item that wasn't ranked by the user (rating == 0)\n",
    "            if rating == 0:\n",
    "                predictionMatrix[user, item] = itemPopularity[item]\n",
    "\n",
    "        ###########         end         ###########\n",
    "        return predictionMatrix    \n",
    "    \n",
    "    def predict_all(self, train_df, num_users, num_items):\n",
    "        \n",
    "        train_matrix = self.processor(train_df, num_users, num_items)\n",
    "        self.__model = self.method(train_matrix, num_users, num_items)\n",
    "        \n",
    "    def evaluate_test(self, test_df, copy=False):\n",
    "        \n",
    "        if copy:\n",
    "            prediction = test_df.copy()\n",
    "        else:\n",
    "            prediction = test_df\n",
    "            \n",
    "        prediction[self.pred_column_name] = np.nan\n",
    "        \n",
    "        for (index, \n",
    "             userID, \n",
    "             itemID) in tqdm(prediction[['userID','itemID']].itertuples()):\n",
    "            prediction.loc[index, self.pred_column_name] = self.__model[userID-1, itemID-1]\n",
    "\n",
    "        return prediction\n",
    "        \n",
    "    def getModel(self):\n",
    "        \"\"\"\n",
    "            return predicted user-item matrix\n",
    "        \"\"\"\n",
    "        return self.__model\n",
    "    \n",
    "    def getPredColName(self):\n",
    "        \"\"\"\n",
    "            return prediction column name\n",
    "        \"\"\"\n",
    "        return self.pred_column_name\n",
    "    \n",
    "    def reset(self):\n",
    "        \"\"\"\n",
    "            reuse the instance of the class by removing model\n",
    "        \"\"\"\n",
    "        try:\n",
    "            self.model = None\n",
    "        except:\n",
    "            print(\"You don not have model..\")\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "XgDw3ALnzdtX"
   },
   "outputs": [],
   "source": [
    "popularity_recsys = BaseLineRecSys('popularity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "wJd50FSdzdta"
   },
   "outputs": [],
   "source": [
    "popularity_recsys.predict_all(rating_df, num_users, num_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "C5TJkUaszdtc"
   },
   "outputs": [],
   "source": [
    "x = popularity_recsys.getModel() #the matrix with filled in ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HN8r3Obtzdtg",
    "outputId": "a0f9ebd2-e6b6-490b-b28b-99e28fd74946"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.all(x<=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 191
    },
    "id": "oZDsDg5Gzdtj",
    "outputId": "d383e3aa-5cdd-4b19-c7c6-be06f63c4c75"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userID</th>\n",
       "      <th>itemID</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>196</td>\n",
       "      <td>242</td>\n",
       "      <td>3</td>\n",
       "      <td>881250949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>186</td>\n",
       "      <td>302</td>\n",
       "      <td>3</td>\n",
       "      <td>891717742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>377</td>\n",
       "      <td>1</td>\n",
       "      <td>878887116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>244</td>\n",
       "      <td>51</td>\n",
       "      <td>2</td>\n",
       "      <td>880606923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>166</td>\n",
       "      <td>346</td>\n",
       "      <td>1</td>\n",
       "      <td>886397596</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userID  itemID  rating  timestamp\n",
       "0     196     242       3  881250949\n",
       "1     186     302       3  891717742\n",
       "2      22     377       1  878887116\n",
       "3     244      51       2  880606923\n",
       "4     166     346       1  886397596"
      ]
     },
     "execution_count": 15,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 207
    },
    "id": "p60BEmn-zdtm",
    "outputId": "915cbf6b-b71e-4e10-8a00-95a43b8eb739"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100000it [01:09, 1441.16it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userID</th>\n",
       "      <th>itemID</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>popularity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>196</td>\n",
       "      <td>242</td>\n",
       "      <td>3</td>\n",
       "      <td>881250949</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>186</td>\n",
       "      <td>302</td>\n",
       "      <td>3</td>\n",
       "      <td>891717742</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>377</td>\n",
       "      <td>1</td>\n",
       "      <td>878887116</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>244</td>\n",
       "      <td>51</td>\n",
       "      <td>2</td>\n",
       "      <td>880606923</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>166</td>\n",
       "      <td>346</td>\n",
       "      <td>1</td>\n",
       "      <td>886397596</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userID  itemID  rating  timestamp  popularity\n",
       "0     196     242       3  881250949         0.0\n",
       "1     186     302       3  891717742         0.0\n",
       "2      22     377       1  878887116         0.0\n",
       "3     244      51       2  880606923         0.0\n",
       "4     166     346       1  886397596         0.0"
      ]
     },
     "execution_count": 16,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "popularity_recsys.evaluate_test(rating_df,copy=True).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "xDu_THj3zdtp"
   },
   "outputs": [],
   "source": [
    "average_user_rating_recsys = BaseLineRecSys('useraverage')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "gQWmspQGzdtr"
   },
   "outputs": [],
   "source": [
    "average_user_rating_recsys.predict_all(rating_df, num_users, num_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yl8uLyIqzdty",
    "outputId": "b47846dd-606f-4f72-8cca-d6283ba21de1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , ..., 3.61029412, 3.61029412,\n",
       "        3.61029412],\n",
       "       [0.        , 3.70967742, 3.70967742, ..., 3.70967742, 3.70967742,\n",
       "        3.70967742],\n",
       "       [2.7962963 , 2.7962963 , 2.7962963 , ..., 2.7962963 , 2.7962963 ,\n",
       "        2.7962963 ],\n",
       "       ...,\n",
       "       [0.        , 4.04545455, 4.04545455, ..., 4.04545455, 4.04545455,\n",
       "        4.04545455],\n",
       "       [4.26582278, 4.26582278, 4.26582278, ..., 4.26582278, 4.26582278,\n",
       "        4.26582278],\n",
       "       [3.41071429, 0.        , 3.41071429, ..., 3.41071429, 3.41071429,\n",
       "        3.41071429]])"
      ]
     },
     "execution_count": 19,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average_user_rating_recsys.getModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 207
    },
    "id": "arSCkkxozdt4",
    "outputId": "d57a2f58-a463-49d3-e48f-3f12271411d8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100000it [01:07, 1481.01it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userID</th>\n",
       "      <th>itemID</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>useraverage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>196</td>\n",
       "      <td>242</td>\n",
       "      <td>3</td>\n",
       "      <td>881250949</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>186</td>\n",
       "      <td>302</td>\n",
       "      <td>3</td>\n",
       "      <td>891717742</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>377</td>\n",
       "      <td>1</td>\n",
       "      <td>878887116</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>244</td>\n",
       "      <td>51</td>\n",
       "      <td>2</td>\n",
       "      <td>880606923</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>166</td>\n",
       "      <td>346</td>\n",
       "      <td>1</td>\n",
       "      <td>886397596</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userID  itemID  rating  timestamp  useraverage\n",
       "0     196     242       3  881250949          0.0\n",
       "1     186     302       3  891717742          0.0\n",
       "2      22     377       1  878887116          0.0\n",
       "3     244      51       2  880606923          0.0\n",
       "4     166     346       1  886397596          0.0"
      ]
     },
     "execution_count": 20,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average_user_rating_recsys.evaluate_test(rating_df,copy=True).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u_RlOlrIzdt7"
   },
   "source": [
    "## Q2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I4zY0XYDzdt7"
   },
   "source": [
    "### (a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "GEQ_IkS3zdt8"
   },
   "outputs": [],
   "source": [
    "class SimBasedRecSys(object):\n",
    "\n",
    "    def __init__(self, base, method, processor=dataPreprocessor):\n",
    "        \"\"\"\n",
    "            base: string. From ['user', 'item']. User-based Similarity or Item-based\n",
    "            method: string. From ['cosine', 'euclidean', 'somethingelse']\n",
    "            processor: function name. dataPreprocessor by default\n",
    "        \"\"\"\n",
    "        self.base = base\n",
    "        self.method_name = method\n",
    "        self.method = self._getMethod(self.method_name)\n",
    "        self.processor = processor\n",
    "        self.pred_column_name = self.base+'-'+self.method_name\n",
    "    \n",
    "    def _getMethod(self, method_name):\n",
    "        \"\"\"\n",
    "            Don't change this\n",
    "        \"\"\"\n",
    "        switcher = {\n",
    "            'cosine': self.cosine,\n",
    "            'euclidean': self.euclidean,\n",
    "            'somethingelse': self.somethingelse,\n",
    "        }\n",
    "        \n",
    "        return switcher[method_name]\n",
    "    \n",
    "    @staticmethod\n",
    "    def cosine(matrix):\n",
    "        \"\"\"\n",
    "            cosine similarity\n",
    "        \"\"\"\n",
    "        similarity_matrix = 1 - pairwise_distances(matrix, metric='cosine') #UxU if user, IxI if item\n",
    "        return similarity_matrix\n",
    "    \n",
    "    @staticmethod\n",
    "    def euclidean(matrix):\n",
    "        \"\"\"\n",
    "            euclidean similarity\n",
    "        \"\"\"\n",
    "        ########### your code goes here ###########\n",
    "        similarity_matrix = 1 / (1 + pairwise_distances(matrix, metric='euclidean')) #UxU if user, IxI if item\n",
    "    \n",
    "        ###########         end         ###########    \n",
    "        \n",
    "        return similarity_matrix\n",
    "    \n",
    "    @staticmethod\n",
    "    def somethingelse(matrix):\n",
    "        \"\"\"\n",
    "            manhattan? or super-natural intuition similarity\n",
    "        \"\"\"\n",
    "        ########### your code goes here ###########\n",
    "        similarity_matrix = 1 / (1 + pairwise_distances(matrix, metric='manhattan')) #UxU if user, IxI if item\n",
    "\n",
    "        ###########         end         ###########        \n",
    "        return similarity_matrix\n",
    "        \n",
    "    def predict_all(self, train_df, num_users, num_items):\n",
    "        \"\"\"\n",
    "            INPUT: \n",
    "                data: pandas DataFrame. columns=['userID', 'itemID', 'rating'...]\n",
    "                num_row: scalar. number of users\n",
    "                num_col: scalar. number of items\n",
    "            OUTPUT:\n",
    "                no return... this method assigns the result to self.model\n",
    "            \n",
    "            NOTES:\n",
    "                self.__model should contain predictions for *all* user and items\n",
    "                (don't worry about predicting for observed (user,item) pairs,\n",
    "                 since we won't be using these predictions in the evaluation)\n",
    "                (see code in for an efficient vectorized example)\n",
    "        \"\"\"\n",
    "        train_matrix = self.processor(train_df, num_users, num_items)\n",
    "        \n",
    "        if self.base == 'user':\n",
    "            ########### your code goes here ###########\n",
    "            # Initialize the predicted rating matrix with zeros\n",
    "            temp_matrix = np.zeros(train_matrix.shape)\n",
    "            #set every single non-zero ratings as 1, for normalization\n",
    "            temp_matrix[train_matrix.nonzero()] = 1\n",
    "            uu_similarity = self.method(train_matrix)\n",
    "            # UxI: UxU mul UxI\n",
    "            normalizer = np.matmul(uu_similarity, temp_matrix)\n",
    "            #for consideration of the NAN value thing\n",
    "            normalizer[normalizer == 0] = 1e-5\n",
    "            predictionMatrix = np.matmul(uu_similarity, train_matrix)/normalizer\n",
    "            #Cold start\n",
    "            # if no one has rated this item before, use user average\n",
    "            useraverage = np.sum(train_matrix, axis=1)/np.sum(temp_matrix, axis=1)\n",
    "            columns = np.sum(predictionMatrix, axis=0)\n",
    "            # if no one has rated this item before, assign the entire item column with user avg rating\n",
    "            predictionMatrix[:, columns==0] = predictionMatrix[:, columns==0] + np.expand_dims(useraverage, axis=1)\n",
    "            self.__model = predictionMatrix\n",
    "            ###########         end         ###########\n",
    "            \n",
    "        elif self.base == 'item':\n",
    "            ########### your code goes here ###########\n",
    "            # Initialize the predicted rating matrix with zeros\n",
    "            temp_matrix = np.zeros(train_matrix.shape)\n",
    "            #set every single non-zero ratings as 1, for normalization\n",
    "            temp_matrix[train_matrix.nonzero()] = 1\n",
    "            ii_similarity = self.method(train_matrix.T)\n",
    "            # IxU: IxI mul IxU\n",
    "            normalizer = np.matmul(ii_similarity, temp_matrix.T)\n",
    "            #for consideration of the NAN value thing\n",
    "            normalizer[normalizer == 0] = 1e-5\n",
    "            predictionMatrix = np.matmul(ii_similarity, train_matrix.T)/normalizer\n",
    "            #Cold start\n",
    "            # if this user has rated nothing, use item average\n",
    "            itemaverage = np.sum(train_matrix, axis=0)/np.sum(temp_matrix, axis=0)\n",
    "            columns = np.sum(predictionMatrix, axis=0)\n",
    "            # if this user has rated nothing, assign the entire user column with item avg rating\n",
    "            predictionMatrix[:, columns==0] = predictionMatrix[:, columns==0] + np.expand_dims(itemaverage, axis=1)\n",
    "            self.__model = predictionMatrix.T\n",
    "            ###########         end         ###########\n",
    "        else:\n",
    "            print('No other option available')\n",
    "        \n",
    "    def evaluate_test(self, test_df, copy=False):\n",
    "        \"\"\"\n",
    "            INPUT:\n",
    "                data: pandas DataFrame. columns=['userID', 'itemID', 'rating'...]\n",
    "            OUTPUT:\n",
    "                predictions:  pandas DataFrame. \n",
    "                              columns=['userID', 'itemID', 'rating', 'base-method'...]\n",
    "                              \n",
    "            NOTE: 1. data can have more columns, but your function should ignore \n",
    "                  additional columns.\n",
    "                  2. 'base-method' depends on your 'base' and 'method'. For example,\n",
    "                  if base == 'user' and method == 'cosine', \n",
    "                  then base-method == 'user-cosine'\n",
    "                  3. your predictions go to 'base-method' column\n",
    "        \"\"\"\n",
    "        if copy:\n",
    "            prediction = test_df.copy()\n",
    "        else:\n",
    "            prediction = test_df\n",
    "        prediction[self.pred_column_name] = np.nan\n",
    "        \n",
    "        for (index, \n",
    "             userID, \n",
    "             itemID) in tqdm(prediction[['userID','itemID']].itertuples()):\n",
    "            prediction.loc[index, self.pred_column_name] = self.__model[userID-1, itemID-1]\n",
    "    \n",
    "        return prediction\n",
    "    \n",
    "    def getModel(self):\n",
    "        \"\"\"\n",
    "            return predicted user-item matrix\n",
    "        \"\"\"\n",
    "        return self.__model\n",
    "    \n",
    "    def getPredColName(self):\n",
    "        \"\"\"\n",
    "            return prediction column name\n",
    "        \"\"\"\n",
    "        return self.pred_column_name\n",
    "    \n",
    "    def reset(self):\n",
    "        \"\"\"\n",
    "            reuse the instance of the class by removing model\n",
    "        \"\"\"\n",
    "        try:\n",
    "            self.model = None\n",
    "        except:\n",
    "            print(\"You do not have model..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RROHVWRpzduA",
    "outputId": "f08a3eac-4a79-4ccc-a1cb-ca1c4dabbf39"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.]])"
      ]
     },
     "execution_count": 22,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Examples of how to call similarity functions.\n",
    "I = np.eye(3)\n",
    "SimBasedRecSys.cosine(I)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZQ5BkzGPzduC",
    "outputId": "6799abbf-be27-4b0a-fe9d-d685816ad54f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.41421356, 0.41421356],\n",
       "       [0.41421356, 1.        , 0.41421356],\n",
       "       [0.41421356, 0.41421356, 1.        ]])"
      ]
     },
     "execution_count": 23,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SimBasedRecSys.euclidean(I)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2V-L-T-PzduF",
    "outputId": "503755c5-06c4-4dab-cd9a-1f3946650074"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.33333333, 0.33333333],\n",
       "       [0.33333333, 1.        , 0.33333333],\n",
       "       [0.33333333, 0.33333333, 1.        ]])"
      ]
     },
     "execution_count": 24,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SimBasedRecSys.somethingelse(I)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IwWjaU4Xhikz"
   },
   "source": [
    "Each metric has its own advantages. But usually we prefer cosine similarity. Since it captures the similarity of what kind of movies are liked by the user. For example, both users give good ratings on movie A but bad ratings on movie B, but their ratings are different. Using cosine similarity in this case will show that they are similar users but Euclidean and Manhatthan similarities will say that they are not that similar due to their different rating score.\n",
    "Cosine similarity measures the variety preference difference between users. Euclidean and Manhattan distances measure the difference due to raring scores for some movies. For example, user A gives movie C and D 2 score and user B gives movie C and D 5 score, the Euclidean and Manhattan capture this difference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "USPsbXpnzduH"
   },
   "source": [
    "### (b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KitojDVdlMcu"
   },
   "source": [
    "The Manhattan distance measrues the absolute differences of the Cartesian coordiantes. If there are outliers amoung users (like the User A and B from the above case). Manhattan metric gives lower similarity than Euclidean metric, demonstrates the user difference better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qDrJogepzduL"
   },
   "source": [
    "## Q3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1Ju9mZE9zduM"
   },
   "source": [
    "### (a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "zAaSIC3BzduM"
   },
   "outputs": [],
   "source": [
    "user_cosine_recsys = SimBasedRecSys('user','cosine')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "dBGVr2_JzduQ"
   },
   "outputs": [],
   "source": [
    "user_cosine_recsys.predict_all(rating_df, num_users, num_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "isW4B7nfzduW",
    "outputId": "9f5d73cc-e577-4869-907b-ad07e78aec63"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.89911175, 3.19022667, 3.0261129 , ..., 2.        , 3.        ,\n",
       "        3.        ],\n",
       "       [3.84034456, 3.17139889, 2.92626717, ..., 2.        , 3.        ,\n",
       "        3.        ],\n",
       "       [3.87104065, 3.12823798, 3.03250708, ..., 2.        , 3.        ,\n",
       "        3.        ],\n",
       "       ...,\n",
       "       [3.90754645, 3.20227238, 3.05776201, ..., 2.        , 3.        ,\n",
       "        3.        ],\n",
       "       [3.91100649, 3.21591021, 2.98854017, ..., 2.        , 3.        ,\n",
       "        3.        ],\n",
       "       [3.91593122, 3.24268207, 3.08255897, ..., 0.        , 3.        ,\n",
       "        3.        ]])"
      ]
     },
     "execution_count": 27,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_cosine_recsys.getModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 191
    },
    "id": "wdxjAZJrzdud",
    "outputId": "465c8c7c-6e08-484a-8b93-05e780f1b585"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userID</th>\n",
       "      <th>itemID</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>196</td>\n",
       "      <td>242</td>\n",
       "      <td>3</td>\n",
       "      <td>881250949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>186</td>\n",
       "      <td>302</td>\n",
       "      <td>3</td>\n",
       "      <td>891717742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>377</td>\n",
       "      <td>1</td>\n",
       "      <td>878887116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>244</td>\n",
       "      <td>51</td>\n",
       "      <td>2</td>\n",
       "      <td>880606923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>166</td>\n",
       "      <td>346</td>\n",
       "      <td>1</td>\n",
       "      <td>886397596</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userID  itemID  rating  timestamp\n",
       "0     196     242       3  881250949\n",
       "1     186     302       3  891717742\n",
       "2      22     377       1  878887116\n",
       "3     244      51       2  880606923\n",
       "4     166     346       1  886397596"
      ]
     },
     "execution_count": 28,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 207
    },
    "id": "yc2PgKylzdug",
    "outputId": "8b100dfa-945b-4134-cc0b-c83d05f4ebff",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100000it [01:21, 1232.51it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userID</th>\n",
       "      <th>itemID</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>user-cosine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>196</td>\n",
       "      <td>242</td>\n",
       "      <td>3</td>\n",
       "      <td>881250949</td>\n",
       "      <td>4.025213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>186</td>\n",
       "      <td>302</td>\n",
       "      <td>3</td>\n",
       "      <td>891717742</td>\n",
       "      <td>4.142828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>377</td>\n",
       "      <td>1</td>\n",
       "      <td>878887116</td>\n",
       "      <td>1.922080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>244</td>\n",
       "      <td>51</td>\n",
       "      <td>2</td>\n",
       "      <td>880606923</td>\n",
       "      <td>3.431884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>166</td>\n",
       "      <td>346</td>\n",
       "      <td>1</td>\n",
       "      <td>886397596</td>\n",
       "      <td>3.424963</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userID  itemID  rating  timestamp  user-cosine\n",
       "0     196     242       3  881250949     4.025213\n",
       "1     186     302       3  891717742     4.142828\n",
       "2      22     377       1  878887116     1.922080\n",
       "3     244      51       2  880606923     3.431884\n",
       "4     166     346       1  886397596     3.424963"
      ]
     },
     "execution_count": 29,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_cosine_recsys.evaluate_test(rating_df,copy=True).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 207
    },
    "id": "0Ic_FKWUzdui",
    "outputId": "91357ccb-d2a9-4290-9ea1-6364f9da64d3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100000it [01:13, 1369.83it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userID</th>\n",
       "      <th>itemID</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>item-cosine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>196</td>\n",
       "      <td>242</td>\n",
       "      <td>3</td>\n",
       "      <td>881250949</td>\n",
       "      <td>3.591314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>186</td>\n",
       "      <td>302</td>\n",
       "      <td>3</td>\n",
       "      <td>891717742</td>\n",
       "      <td>3.344077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>377</td>\n",
       "      <td>1</td>\n",
       "      <td>878887116</td>\n",
       "      <td>2.965365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>244</td>\n",
       "      <td>51</td>\n",
       "      <td>2</td>\n",
       "      <td>880606923</td>\n",
       "      <td>3.637332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>166</td>\n",
       "      <td>346</td>\n",
       "      <td>1</td>\n",
       "      <td>886397596</td>\n",
       "      <td>3.333013</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userID  itemID  rating  timestamp  item-cosine\n",
       "0     196     242       3  881250949     3.591314\n",
       "1     186     302       3  891717742     3.344077\n",
       "2      22     377       1  878887116     2.965365\n",
       "3     244      51       2  880606923     3.637332\n",
       "4     166     346       1  886397596     3.333013"
      ]
     },
     "execution_count": 58,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_cosine_recsys = SimBasedRecSys('item','cosine')\n",
    "item_cosine_recsys.predict_all(rating_df, num_users, num_items)\n",
    "item_cosine_recsys.evaluate_test(rating_df,copy=True).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pZdTvp_szduk"
   },
   "source": [
    "### (b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "k-BnXbsLzdul"
   },
   "outputs": [],
   "source": [
    "class CrossValidation(object):\n",
    "    def __init__(self, metric, data_path=MOVIELENS_DIR):\n",
    "        \"\"\"\n",
    "            INPUT:\n",
    "                metric: string. from['RMSE','P@K','R@K']\n",
    "        \"\"\"\n",
    "        self.folds = self._getData(MOVIELENS_DIR)\n",
    "        self.metric_name = metric\n",
    "        self.metric = self._getMetric(self.metric_name)\n",
    "        \n",
    "    def _getMetric(self, metric_name):\n",
    "        \"\"\"\n",
    "            Don't change this\n",
    "        \"\"\"\n",
    "        switcher = {\n",
    "            'RMSE': self.rmse,\n",
    "            'P@K': self.patk,\n",
    "            'R@K': self.ratk,\n",
    "            'RPrecision': self.rprecision\n",
    "        }\n",
    "        \n",
    "        return switcher[metric_name]\n",
    "    \n",
    "    @staticmethod\n",
    "    def rmse(data, k, num_users, num_items, pred, true='rating'):\n",
    "        \"\"\"\n",
    "            data: pandas DataFrame. \n",
    "            pred: string. Column name that corresponding to the prediction\n",
    "            true: string. Column name that corresponding to the true rating\n",
    "        \"\"\"\n",
    "        return sqrt(mean_squared_error(data[pred], data[true]))\n",
    "    \n",
    "    # Precision at k\n",
    "    def patk(self, data, k, num_users, num_items, pred, true='rating'):\n",
    "        \"\"\"\n",
    "            data: pandas DataFrame. \n",
    "            k: top-k items retrived\n",
    "            pred: string. Column name that corresponding to the prediction\n",
    "            true: string. Column name that corresponding to the true rating\n",
    "        \"\"\"\n",
    "        prediction = self.getMatrix(data, num_users, num_items, pred)\n",
    "        testSet =  self.getMatrix(data, num_users, num_items, true)\n",
    "    \n",
    "        # Initialize sum and count vars for average calculation\n",
    "        sumPrecisions = 0\n",
    "        countPrecisions = 0\n",
    "\n",
    "        # Define function for converting 1-5 rating to 0/1 (like / don't like)\n",
    "        vf = np.vectorize(lambda x: 1 if x >= 4 else 0)\n",
    "\n",
    "        for userID in range(num_users):\n",
    "            # Pick top K based on predicted rating\n",
    "            userVector = prediction[userID,:]\n",
    "            topK = nlargest(k, range(len(userVector)), userVector.take) #return the indices for the top k largest values in prediction\n",
    "\n",
    "            # Convert test set ratings to like / don't like\n",
    "            userTestVector = vf(testSet[userID,:]).nonzero()[0] #return the indices for those 'like' in test\n",
    "\n",
    "            # Calculate precision\n",
    "            precision = float(len([item for item in topK if item in userTestVector]))/len(topK)\n",
    "\n",
    "            # Update sum and count\n",
    "            sumPrecisions += precision\n",
    "            countPrecisions += 1\n",
    "\n",
    "        # Return average P@k\n",
    "        return float(sumPrecisions)/countPrecisions\n",
    "    \n",
    "    # Recall at k\n",
    "    def ratk(self, data, k, num_users, num_items, pred, true='rating'):\n",
    "        \"\"\"\n",
    "            data: pandas DataFrame. \n",
    "            k: top-k items relevant\n",
    "            pred: string. Column name that corresponding to the prediction\n",
    "            true: string. Column name that corresponding to the true rating\n",
    "        \"\"\"\n",
    "        prediction = self.getMatrix(data, num_users, num_items, pred)\n",
    "        testSet =  self.getMatrix(data, num_users, num_items, true)\n",
    "        # Initialize sum and count vars for average calculation\n",
    "        sumRecalls = 0\n",
    "        countRecalls = 0\n",
    "\n",
    "        # Define function for converting 1-5 rating to 0/1 (like / don't like)\n",
    "        vf = np.vectorize(lambda x: 1 if x >= 4 else 0)\n",
    "\n",
    "        for userID in range(num_users):\n",
    "            # Pick top K based on predicted rating\n",
    "            userVector = prediction[userID,:]\n",
    "            topK = nlargest(k, range(len(userVector)), userVector.take) #return the indices for the top k largest values in prediction\n",
    "\n",
    "            # Convert test set ratings to like / don't like\n",
    "            userTestVector = vf(testSet[userID,:]).nonzero()[0] #return the indices for those 'like' in test\n",
    "\n",
    "            # Ignore user if has no ratings in the test set\n",
    "            if (len(userTestVector) == 0):\n",
    "                continue\n",
    "\n",
    "            # Calculate recall\n",
    "            recall = float(len([item for item in topK if item in userTestVector]))/len(userTestVector)\n",
    "\n",
    "            # Update sum and count\n",
    "            sumRecalls += recall\n",
    "            countRecalls += 1\n",
    "\n",
    "        # Return average R@k\n",
    "        return float(sumRecalls)/countRecalls\n",
    "\n",
    "    def rprecision(self, data, k, num_users, num_items, pred, true='rating'):\n",
    "        \"\"\"\n",
    "            data: pandas DataFrame.\n",
    "            k: top-k items relevant\n",
    "            pred: string. Column name that corresponding to the prediction\n",
    "            true: string. Column name that corresponding to the true rating\n",
    "        \"\"\"\n",
    "        prediction = self.getMatrix(data, num_users, num_items, pred)\n",
    "        testSet = self.getMatrix(data, num_users, num_items, true)\n",
    "        # Initialize sum and count vars for average calculation\n",
    "        sumRPs = 0\n",
    "        countRPs = 0\n",
    "\n",
    "        # Define function for converting 1-5 rating to 0/1 (like / don't like)\n",
    "        vf = np.vectorize(lambda x: 1 if x >= 4 else 0)\n",
    "\n",
    "        for userID in range(num_users):\n",
    "            # Pick top K based on predicted rating\n",
    "            userVector = prediction[userID, :]\n",
    "\n",
    "\n",
    "            # Convert test set ratings to like / don't like\n",
    "            userTestVector = vf(testSet[userID, :]).nonzero()[0]  #return the indices for those 'like' in test\n",
    "\n",
    "            # Ignore user if has no ratings in the test set\n",
    "            if (len(userTestVector) == 0):\n",
    "                continue\n",
    "\n",
    "            topK = nlargest(len(userTestVector), range(len(userVector)), userVector.take) #return the indices for the top k largest values in prediction where k = num of total 'like' is test\n",
    "            # Calculate recall\n",
    "            rp = float(len([item for item in topK if item in userTestVector])) / len(userTestVector)\n",
    "\n",
    "            # Update sum and count\n",
    "            sumRPs += rp\n",
    "            countRPs += 1\n",
    "\n",
    "        # Return average R@k\n",
    "        return float(sumRPs) / countRPs\n",
    "\n",
    "    @staticmethod\n",
    "    def getMatrix(rating_df, num_users, num_items, column_name): #same as Preprocessor\n",
    "        matrix = np.zeros((num_users, num_items))\n",
    "    \n",
    "        for (index, userID, itemID, value) in rating_df[['userID','itemID', column_name]].itertuples():\n",
    "            matrix[userID-1, itemID-1] = value\n",
    "            \n",
    "        return matrix\n",
    "    \n",
    "    @staticmethod\n",
    "    def _getData(data_path):\n",
    "        \"\"\"\n",
    "            Don't change this function\n",
    "        \"\"\"\n",
    "        folds = []\n",
    "        data_types = ['u{0}.base','u{0}.test']\n",
    "        for i in range(1,6):\n",
    "            train_set = getData(data_path, data_types[0].format(i))\n",
    "            test_set = getData(data_path, data_types[1].format(i))\n",
    "            folds.append([train_set, test_set])\n",
    "        return folds\n",
    "    \n",
    "    def run(self, algorithms, num_users, num_items, k=1):\n",
    "        \"\"\"\n",
    "            5-fold cross-validation\n",
    "            algorithms: list. a list of algorithms. \n",
    "                        eg: [user_cosine_recsys, item_euclidean_recsys]\n",
    "        \"\"\"\n",
    "        \n",
    "        scores = {}\n",
    "        for algorithm in algorithms:\n",
    "            print('Processing algorithm {0}'.format(algorithm.getPredColName()))\n",
    "            fold_scores = []\n",
    "            for fold in self.folds:\n",
    "                algorithm.reset()\n",
    "                algorithm.predict_all(fold[0], num_users, num_items)\n",
    "                prediction = algorithm.evaluate_test(fold[1])\n",
    "                pred_col = algorithm.getPredColName()\n",
    "                fold_scores.append(self.metric(prediction, k, num_users, num_items, pred_col))\n",
    "                \n",
    "            mean = np.mean(fold_scores)\n",
    "            ci_low, ci_high = stats.t.interval(0.95, len(fold_scores)-1, loc=mean, scale=stats.sem(fold_scores))\n",
    "            scores[algorithm.getPredColName()] = [fold_scores, mean, ci_low, ci_high]\n",
    "            \n",
    "        results = scores    \n",
    "    \n",
    "        return results\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "eJKyb9l-zdun"
   },
   "outputs": [],
   "source": [
    "# How to use CrossValidation Class?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "CU3rZPtnzdus"
   },
   "outputs": [],
   "source": [
    "# 1. gather your algorithms in previous steps.\n",
    "algorithm_instances = [item_cosine_recsys, \n",
    "                       user_cosine_recsys]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "xf-m7d5Dzdux"
   },
   "outputs": [],
   "source": [
    "# 2. Instantiate a CrossValidation instance and assign the measurement that you want to use\n",
    "# RMSE, P@K, RPrecision\n",
    "# Precision at K in this example\n",
    "cv_patk = CrossValidation('RMSE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XqcihyZdzduz",
    "outputId": "43cfa6c5-335c-4a3e-a746-932a1f8edd1b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing algorithm item-cosine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:110: RuntimeWarning: invalid value encountered in true_divide\n",
      "20000it [00:06, 3246.01it/s]\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:110: RuntimeWarning: invalid value encountered in true_divide\n",
      "20000it [00:06, 3275.21it/s]\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:110: RuntimeWarning: invalid value encountered in true_divide\n",
      "20000it [00:06, 3315.67it/s]\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:110: RuntimeWarning: invalid value encountered in true_divide\n",
      "20000it [00:06, 3312.45it/s]\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:110: RuntimeWarning: invalid value encountered in true_divide\n",
      "20000it [00:06, 3260.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing algorithm user-cosine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20000it [00:06, 3249.99it/s]\n",
      "20000it [00:06, 3307.07it/s]\n",
      "20000it [00:06, 3286.08it/s]\n",
      "20000it [00:06, 3276.18it/s]\n",
      "20000it [00:06, 3239.82it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'item-cosine': [[1.0377631264364244,\n",
       "   1.0207280585350078,\n",
       "   1.0101820660011798,\n",
       "   1.0136832839209695,\n",
       "   1.0180579656376574],\n",
       "  1.020082900106248,\n",
       "  1.0068242686250732,\n",
       "  1.0333415315874226],\n",
       " 'user-cosine': [[1.026449013124381,\n",
       "   1.0214387664779507,\n",
       "   1.0132940326457187,\n",
       "   1.0094003999022947,\n",
       "   1.0161883961525586],\n",
       "  1.0173541216605808,\n",
       "  1.009013080226148,\n",
       "  1.0256951630950135]}"
      ]
     },
     "execution_count": 61,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3. Run CV by giving:\n",
    "#    1> algorithms just gathered\n",
    "#    2> number of users in the full dataset\n",
    "#    3> number of items in the full dataset\n",
    "#    4> precision or recall at K need a K value, so k=5 means precision at 5 in this example\n",
    "# Results include independent results from 5 folds, their mean, and confidence interval.\n",
    "cv_patk.run(algorithm_instances, num_users, num_items,k=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TLA5yjXym4MK"
   },
   "source": [
    "User-cosine based collaborative filtering works slighter better than item-cosine based because the avergae number of ratings per user could be higher than the average number of ratings per item. meaning that the item cold-start problem is more susceptible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nJCFpLY25JuY"
   },
   "source": [
    "## Q4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RMdW5aLG5OTH"
   },
   "source": [
    "### (a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "AI1hS4CP5RVP"
   },
   "outputs": [],
   "source": [
    "class PMFRecSys(object):\n",
    "    def __init__(self, num_feat=10, epsilon=1, _lambda=0.1, momentum=0.8, maxepoch=20, num_batches=10, batch_size=1000):\n",
    "        \"\"\"\n",
    "            num_feat: int, number of latent features\n",
    "            epsilon: float, learning rate\n",
    "            _lambda: float, L2 regularization,\n",
    "            momentum: float, momentum of the gradient,\n",
    "            maxepoch: float, Number of epoch before stop,\n",
    "            num_batches: int, Number of batches in each epoch (for SGD optimization),\n",
    "            batch_size:Number int, of training samples used in each batches (for SGD optimization)\n",
    "            \n",
    "        \"\"\"\n",
    "        self.num_feat = num_feat  # Number of latent features,\n",
    "        self.epsilon = epsilon  # learning rate,\n",
    "        self._lambda = _lambda  # L2 regularization,\n",
    "        self.momentum = momentum  # momentum of the gradient,\n",
    "        self.maxepoch = maxepoch  # Number of epoch before stop,\n",
    "        self.num_batches = num_batches  # Number of batches in each epoch (for SGD optimization),\n",
    "        self.batch_size = batch_size  # Number of training samples used in each batches (for SGD optimization)\n",
    "        self.test = False\n",
    "        self.w_Item = None  # Item feature vectors\n",
    "        self.w_User = None  # User feature vectors\n",
    "        \n",
    "        self.rmse_train = []\n",
    "        self.rmse_test = []\n",
    "        self.pred_column_name='PMF'\n",
    "\n",
    "    def predict_all(self, train_vec, num_user, num_item):\n",
    "        \"\"\"\n",
    "            INPUT: \n",
    "                data: pandas DataFrame. columns=['userID', 'itemID', 'rating'...]\n",
    "                num_user: scalar. number of users\n",
    "                num_item: scalar. number of items\n",
    "            OUTPUT:\n",
    "                no return... this method update w_User and w_Item\n",
    "            \n",
    "            NOTES:\n",
    "                self.W_Item and self.W_User are use to do the final predition for a user\n",
    "                \n",
    "        \"\"\"\n",
    "        # select 'userID', 'itemID', 'rating only\n",
    "        train_vec = train_vec.iloc[:, :3].values #get the 10000x3 matrix,\n",
    "        if self.test:\n",
    "          train_vec, val_vec = train_test_split(train_vec) #default test set size\n",
    "          pairs_val = val_vec.shape[0] #number of records in test set\n",
    "          self.mean_rating_test = np.mean(val_vec[:, 2])  #avg rating for test set\n",
    "        self.mean_rating_train = np.mean(train_vec[:, 2])  # avg rating for train set\n",
    "        pairs_train = train_vec.shape[0]  # num of records in tain set\n",
    "        \n",
    "\n",
    "        # to avoid out of bound\n",
    "        num_user += 1  \n",
    "        num_item += 1  \n",
    "        # initialize\n",
    "        self.epoch = 0\n",
    "        \n",
    "        ########### your code goes here ###########\n",
    "    \n",
    "        self.w_Item = sqrt(0.1) * np.random.randn(num_item, self.num_feat)  # item M x D(latent feature) \n",
    "        self.w_User = sqrt(0.1) * np.random.randn(num_user, self.num_feat)  # user N x D(latent feature) \n",
    "    \n",
    "    \n",
    "        ###########         end         ###########  \n",
    "\n",
    "        self.w_Item_inc = np.zeros((num_item, self.num_feat))  # accumulate the gradient\n",
    "        self.w_User_inc = np.zeros((num_user, self.num_feat))  # accumulate the gradient\n",
    "        while self.epoch < self.maxepoch: \n",
    "            self.epoch += 1\n",
    "\n",
    "            # Shuffle training truples\n",
    "            shuffled_order = np.arange(train_vec.shape[0])  \n",
    "            np.random.shuffle(shuffled_order)  #shuffle the above order every time\n",
    "\n",
    "            # Batch update\n",
    "            for batch in range(self.num_batches): \n",
    "                # print \"epoch %d batch %d\" % (self.epoch, batch+1)\n",
    "\n",
    "                test = np.arange(self.batch_size * batch, self.batch_size * (batch + 1)) # get each batch\n",
    "                batch_idx = np.mod(test, shuffled_order.shape[0])  # get the real data index\n",
    "\n",
    "\n",
    "                batch_UserID = np.array(train_vec[shuffled_order[batch_idx], 0], dtype='int32')\n",
    "                batch_ItemID = np.array(train_vec[shuffled_order[batch_idx], 1], dtype='int32')\n",
    "\n",
    "                # Compute Compute mean rating subtracted rating  \n",
    "                ########### your code goes here ###########\n",
    "            \n",
    "                pred_out = np.sum(np.multiply(self.w_User[batch_UserID, :], self.w_Item[batch_ItemID, :]), axis = 1) #size (batch_size, )\n",
    "            \n",
    "            \n",
    "                ###########         end         ########### \n",
    "\n",
    "                rawErr = pred_out + self.mean_rating_train - train_vec[shuffled_order[batch_idx], 2]\n",
    "\n",
    "                # Compute gradients\n",
    "                Ix_User = 2 * np.multiply(rawErr[:, np.newaxis], self.w_Item[batch_ItemID, :]) \\\n",
    "                       + self._lambda * self.w_User[batch_UserID, :]\n",
    "                Ix_Item = 2 * np.multiply(rawErr[:, np.newaxis], self.w_User[batch_UserID, :]) \\\n",
    "                       + self._lambda * (self.w_Item[batch_ItemID, :])  # np.newaxis :increase the dimension\n",
    "\n",
    "                dw_Item = np.zeros((num_item, self.num_feat))\n",
    "                dw_User = np.zeros((num_user, self.num_feat))\n",
    "\n",
    "                # loop to aggreate the gradients of the same element\n",
    "                for i in range(self.batch_size):\n",
    "                    dw_Item[batch_ItemID[i], :] += Ix_Item[i, :]\n",
    "                    dw_User[batch_UserID[i], :] += Ix_User[i, :]\n",
    "\n",
    "                # Update with momentum\n",
    "                self.w_Item_inc = self.momentum * self.w_Item_inc + self.epsilon * dw_Item / self.batch_size\n",
    "                self.w_User_inc = self.momentum * self.w_User_inc + self.epsilon * dw_User / self.batch_size\n",
    "\n",
    "                self.w_Item = self.w_Item - self.w_Item_inc\n",
    "                self.w_User = self.w_User - self.w_User_inc\n",
    "\n",
    "                # Compute Compute mean rating subtracted rating \n",
    "                if batch == self.num_batches - 1:\n",
    "                    train_user_idx = np.array(train_vec[:, 0], dtype='int32')\n",
    "                    train_item_idx = np.array(train_vec[:, 1], dtype='int32')\n",
    "                    ########### your code goes here ###########\n",
    "            \n",
    "                    pred_out = np.sum(np.multiply(self.w_User[train_user_idx, :], self.w_Item[train_item_idx, :]), axis = 1) # size(pairs_train, )\n",
    "            \n",
    "            \n",
    "                    ###########         end         ########### \n",
    "                    rawErr = pred_out + self.mean_rating_train - train_vec[:, 2] \n",
    "                    obj = np.linalg.norm(rawErr) ** 2 \\\n",
    "                          + 0.5 * self._lambda * (np.linalg.norm(self.w_User) ** 2 + np.linalg.norm(self.w_Item) ** 2)\n",
    "\n",
    "                    self.rmse_train.append(np.sqrt(obj / pairs_train))\n",
    "\n",
    "                # Compute validation error\n",
    "                if batch == self.num_batches - 1 and self.test:\n",
    "                    val_user_idx = np.array(val_vec[:, 0], dtype='int32')\n",
    "                    val_item_idx = np.array(val_vec[:, 1], dtype='int32')\n",
    "                    ########### your code goes here ###########\n",
    "            \n",
    "                    pred_out = np.sum(np.multiply(self.w_User[val_user_idx, :], self.w_Item[val_item_idx, :]), axis = 1) #size(pairs_val, )\n",
    "            \n",
    "            \n",
    "                    ###########         end         ########### \n",
    "                    rawErr = pred_out + self.mean_rating_test - val_vec[:, 2]\n",
    "                    self.rmse_test.append(np.linalg.norm(rawErr) / np.sqrt(pairs_val))\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "    def evaluate_test(self, test_df, copy=False):\n",
    "        \"\"\"\n",
    "            INPUT:\n",
    "                data: pandas DataFrame. columns=['userID', 'itemID', 'rating'...]\n",
    "            OUTPUT:\n",
    "                predictions:  pandas DataFrame. \n",
    "                              columns=['userID', 'itemID', 'rating', 'base-method'...]\n",
    "                              \n",
    "        \"\"\"\n",
    "        if copy:\n",
    "            prediction = pd.DataFrame(test_df.copy(), columns=['userID', 'itemID', 'rating'])\n",
    "        else:\n",
    "            prediction = pd.DataFrame(test_df, columns=['userID', 'itemID', 'rating'])\n",
    "        prediction[self.pred_column_name] = np.nan\n",
    "        \n",
    "        for (index, \n",
    "             userID, \n",
    "             itemID) in tqdm(prediction[['userID','itemID']].itertuples()):\n",
    "            prediction.loc[index, self.pred_column_name] = (np.dot(self.w_Item, self.w_User[int(userID), :]) + self.mean_rating_train)[int(itemID)]\n",
    "    \n",
    "        return prediction\n",
    "    \n",
    "    def plot_error(self):\n",
    "      if self.test:\n",
    "        plt.plot(range(pmf.maxepoch), pmf.rmse_test, marker='v', label='Test Data')\n",
    "      plt.plot(range(pmf.maxepoch), pmf.rmse_train, marker='o', label='Training Data')\n",
    "      plt.title('The MovieLens Dataset Learning Curve')\n",
    "      plt.xlabel('Number of Epochs')\n",
    "      plt.ylabel('RMSE')\n",
    "      plt.legend()\n",
    "      plt.grid()\n",
    "      plt.show()\n",
    "          \n",
    "    def getPredColName(self):\n",
    "        \"\"\"\n",
    "            return prediction column name\n",
    "        \"\"\"\n",
    "        return self.pred_column_name\n",
    "    \n",
    "    def reset(self):\n",
    "        \"\"\"\n",
    "            reuse the instance of the class by removing model\n",
    "        \"\"\"\n",
    "        try:\n",
    "            self.w_Item = None \n",
    "            self.w_User = None \n",
    "        except:\n",
    "            print(\"You do not have w_Item, w_User\")\n",
    "\n",
    "    def set_params(self, parameters):\n",
    "        if isinstance(parameters, dict):\n",
    "            self.num_feat = parameters.get(\"num_feat\", 10)\n",
    "            self.epsilon = parameters.get(\"epsilon\", 1)\n",
    "            self._lambda = parameters.get(\"_lambda\", 0.1)\n",
    "            self.momentum = parameters.get(\"momentum\", 0.8)\n",
    "            self.maxepoch = parameters.get(\"maxepoch\", 20)\n",
    "            self.num_batches = parameters.get(\"num_batches\", 10)\n",
    "            self.batch_size = parameters.get(\"batch_size\", 1000)\n",
    "            self.test = parameters.get(\"test_mode\", False)\n",
    "        else:\n",
    "          raise Exception(\"You need to pass in a dictionary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "ce7wlxycY76k"
   },
   "outputs": [],
   "source": [
    "pmf = PMFRecSys()\n",
    "pmf.set_params({\"num_feat\": 10, \"epsilon\": 1, \"_lambda\": 0.1, \"momentum\": 0.8, \"maxepoch\": 100, \"num_batches\": 100,\n",
    "                \"batch_size\": 1000, 'test_mode':False})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "id": "p56cFny7Y_Z_",
    "outputId": "8ffdcee5-9a5b-4ae3-841f-90fba5eed91f"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pmf.predict_all(rating_df, num_users, num_items)\n",
    "pmf.plot_error()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RcDThBootXZN"
   },
   "source": [
    "After I set the test_mode to 'True', I found that the best number of epoches is 20. When >20, the test RMSE starts increasing although the tain RMSE still decreases, meaning there is an overfitting problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-tkSLeDqzdu1"
   },
   "source": [
    "## Q5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "00OSiRl9zdu2"
   },
   "source": [
    "### (a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YS4qfLOAzdu2",
    "outputId": "cfa87abf-faba-4d0e-c6f1-f13de4a36ecf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric: RMSE\n",
      "Processing algorithm popularity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20000it [00:06, 3276.19it/s]\n",
      "20000it [00:06, 3304.15it/s]\n",
      "20000it [00:06, 3298.54it/s]\n",
      "20000it [00:06, 3258.43it/s]\n",
      "20000it [00:06, 3267.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing algorithm useraverage\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20000it [00:06, 3256.80it/s]\n",
      "20000it [00:06, 3317.56it/s]\n",
      "20000it [00:05, 3339.45it/s]\n",
      "20000it [00:06, 3250.57it/s]\n",
      "20000it [00:06, 3301.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing algorithm user-cosine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20000it [00:06, 3274.69it/s]\n",
      "20000it [00:06, 3300.30it/s]\n",
      "20000it [00:06, 3324.53it/s]\n",
      "20000it [00:06, 3301.11it/s]\n",
      "20000it [00:06, 3299.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing algorithm PMF\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20000it [00:11, 1796.54it/s]\n",
      "20000it [00:11, 1758.47it/s]\n",
      "20000it [00:11, 1801.19it/s]\n",
      "20000it [00:11, 1782.34it/s]\n",
      "20000it [00:11, 1778.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric: P@K\n",
      "Processing algorithm popularity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20000it [00:06, 3267.04it/s]\n",
      "20000it [00:06, 3285.03it/s]\n",
      "20000it [00:06, 3279.83it/s]\n",
      "20000it [00:06, 3299.92it/s]\n",
      "20000it [00:06, 3313.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing algorithm useraverage\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20000it [00:06, 3275.54it/s]\n",
      "20000it [00:06, 3232.52it/s]\n",
      "20000it [00:06, 3226.39it/s]\n",
      "20000it [00:06, 3239.08it/s]\n",
      "20000it [00:06, 3252.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing algorithm user-cosine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20000it [00:06, 3301.95it/s]\n",
      "20000it [00:06, 3261.92it/s]\n",
      "20000it [00:06, 3244.96it/s]\n",
      "20000it [00:06, 3229.63it/s]\n",
      "20000it [00:06, 3251.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing algorithm PMF\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20000it [00:10, 1845.83it/s]\n",
      "20000it [00:11, 1750.55it/s]\n",
      "20000it [00:11, 1747.11it/s]\n",
      "20000it [00:11, 1779.59it/s]\n",
      "20000it [00:11, 1792.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric: RPrecision\n",
      "Processing algorithm popularity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20000it [00:06, 3240.38it/s]\n",
      "20000it [00:06, 3194.80it/s]\n",
      "20000it [00:06, 3250.06it/s]\n",
      "20000it [00:06, 3242.62it/s]\n",
      "20000it [00:06, 3295.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing algorithm useraverage\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20000it [00:06, 3250.69it/s]\n",
      "20000it [00:06, 3216.49it/s]\n",
      "20000it [00:06, 3236.33it/s]\n",
      "20000it [00:06, 3191.74it/s]\n",
      "20000it [00:06, 3213.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing algorithm user-cosine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20000it [00:06, 3315.20it/s]\n",
      "20000it [00:06, 3233.17it/s]\n",
      "20000it [00:06, 3188.67it/s]\n",
      "20000it [00:06, 3242.35it/s]\n",
      "20000it [00:06, 3245.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing algorithm PMF\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20000it [00:11, 1765.83it/s]\n",
      "20000it [00:11, 1737.34it/s]\n",
      "20000it [00:11, 1756.66it/s]\n",
      "20000it [00:11, 1754.11it/s]\n",
      "20000it [00:11, 1790.47it/s]\n"
     ]
    }
   ],
   "source": [
    "algorithm_instances = [popularity_recsys, \n",
    "                       average_user_rating_recsys, \n",
    "                       user_cosine_recsys,\n",
    "                       pmf]\n",
    "metrics = ['RMSE','P@K','RPrecision']\n",
    "performance = {}\n",
    "for metric in metrics:\n",
    "    print('Metric:', metric)\n",
    "    cv = CrossValidation(metric)\n",
    "    results = cv.run(algorithm_instances, num_users, num_items, k=5)\n",
    "    performance[metric] = results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "H3XpBlut4cfH",
    "outputId": "d9d8e262-2ff3-44e2-c72d-7596ad968c9a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------RMSE--------------------\n",
      "   Algorithm        Mean    CI_lower    CI_upper\n",
      "  popularity       3.159       3.139       3.179\n",
      " useraverage       1.044       1.029       1.059\n",
      " user-cosine       1.017       1.009       1.026\n",
      "         PMF       0.971       0.957       0.985\n",
      "---------------------P@K--------------------\n",
      "   Algorithm        Mean    CI_lower    CI_upper\n",
      "  popularity       0.551       0.405       0.696\n",
      " useraverage       0.474       0.342       0.605\n",
      " user-cosine       0.556        0.41       0.702\n",
      "         PMF       0.547       0.404       0.691\n",
      "---------------------RPrecision--------------------\n",
      "   Algorithm        Mean    CI_lower    CI_upper\n",
      "  popularity       0.718       0.707       0.729\n",
      " useraverage       0.646        0.64       0.652\n",
      " user-cosine       0.721        0.71       0.732\n",
      "         PMF       0.714       0.703       0.726\n"
     ]
    }
   ],
   "source": [
    "for metric in performance:\n",
    "    print('---------------------{}--------------------'.format(metric))\n",
    "    print('{:>12}{:>12}{:>12}{:>12}'.format('Algorithm','Mean','CI_lower','CI_upper'))\n",
    "    for algorithm in performance[metric]:\n",
    "        print('{:>12}{:>12}{:>12}{:>12}'.format(algorithm,round(performance[metric][algorithm][1], 3),round(performance[metric][algorithm][2], 3),round(performance[metric][algorithm][3], 3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4ndWFEgUzdu4"
   },
   "source": [
    "### (b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QKzju59buFSg"
   },
   "source": [
    "*   Useraverage based cannot be evaluated with P@K and RPrecision. Since for all the unrated movies, we set the ratings as user average rating, meaning that all the unrated movies will have the same rating for a user. When we calculate P@K and RPrecision, this may have effects on the ranking of the rating scores for each user. \n",
    "*   Popularity based cannot be evaluated by RMSE since the popularity is measured by # of user liked / # of user rated which means the popularity is between [0,1] while the true rating should be between 1-5. This will give very big RMSE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LkjR-wdw4NOJ"
   },
   "source": [
    "### (c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E44-jJGF4Oxi"
   },
   "source": [
    "*  For RMSE, PMF works best since PMF is an optimizaiton problem that we exploit the latent varibles and optimize the decompossed matices to minimize the error between the prediciton and the real rating.\n",
    "\n",
    "*  For P@K, user-cosine works best since user-cosine utilizes the similarity between users and since the ratings are predicted based on other similar users, if other similar users like the movie, the target user may like the movie as well and the prediction rating will be higher. Therefore, the top recommended movies will be more accurate since they are predicted based on other similar users' preference.\n",
    "*  For RPrecision, user-cosine works best and the reason is the same as P@K."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_82YWdnJ60Sv"
   },
   "source": [
    "### (d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tf09-GFb61p6"
   },
   "source": [
    "*  Perfect RMSE implies perfect ranking, but good RMSE is not required for good ranking. A perfect RMSE indicates well generation of the learned model which gives better rankings. But a decent/good RMSE does not have perfect generation which means those high ratings samples may not be generated well(the low rating samples may be generated well which could also lead to a decent RMSE).\n",
    "*  A good ranking metrics does not imply good RMSE since the ranking metrics focus on the top k items. If the other items  perform bad but it can still give good performance using ranking metrics while the RMSE will be bad."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wkx8GW4wzdu8"
   },
   "source": [
    "## Q6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HnLcDctYzdu9"
   },
   "source": [
    "### (a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 325
    },
    "id": "F16agjyHzdu_",
    "outputId": "b52cf2e1-6f85-497e-8ee9-c32b48d3c8be"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieID</th>\n",
       "      <th>movieTitle</th>\n",
       "      <th>releaseDate</th>\n",
       "      <th>videoReleaseDate</th>\n",
       "      <th>IMDbURL</th>\n",
       "      <th>unknown</th>\n",
       "      <th>action</th>\n",
       "      <th>adventure</th>\n",
       "      <th>animation</th>\n",
       "      <th>childrens</th>\n",
       "      <th>comedy</th>\n",
       "      <th>crime</th>\n",
       "      <th>documentary</th>\n",
       "      <th>drama</th>\n",
       "      <th>fantasy</th>\n",
       "      <th>filmNoir</th>\n",
       "      <th>horror</th>\n",
       "      <th>musical</th>\n",
       "      <th>mystery</th>\n",
       "      <th>romance</th>\n",
       "      <th>sciFi</th>\n",
       "      <th>thriller</th>\n",
       "      <th>war</th>\n",
       "      <th>western</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>01-Jan-1995</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?Toy%20Story%2...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>GoldenEye (1995)</td>\n",
       "      <td>01-Jan-1995</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?GoldenEye%20(...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Four Rooms (1995)</td>\n",
       "      <td>01-Jan-1995</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?Four%20Rooms%...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Get Shorty (1995)</td>\n",
       "      <td>01-Jan-1995</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?Get%20Shorty%...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Copycat (1995)</td>\n",
       "      <td>01-Jan-1995</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?Copycat%20(1995)</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movieID         movieTitle  releaseDate  ...  thriller war  western\n",
       "0        1   Toy Story (1995)  01-Jan-1995  ...         0   0        0\n",
       "1        2   GoldenEye (1995)  01-Jan-1995  ...         1   0        0\n",
       "2        3  Four Rooms (1995)  01-Jan-1995  ...         1   0        0\n",
       "3        4  Get Shorty (1995)  01-Jan-1995  ...         0   0        0\n",
       "4        5     Copycat (1995)  01-Jan-1995  ...         1   0        0\n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fieldsMovies = ['movieID', 'movieTitle', 'releaseDate', 'videoReleaseDate', 'IMDbURL', 'unknown', 'action', 'adventure',\n",
    "          'animation', 'childrens', 'comedy', 'crime', 'documentary', 'drama', 'fantasy', 'filmNoir', 'horror',\n",
    "          'musical', 'mystery', 'romance','sciFi', 'thriller', 'war', 'western']\n",
    "moviesDF = pd.read_csv(os.path.join(MOVIELENS_DIR, 'u.item'), sep='|', names=fieldsMovies, encoding='latin-1')\n",
    "moviesDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "6AstiHISK6cA"
   },
   "outputs": [],
   "source": [
    "User_Item_Matix = dataPreprocessor(rating_df, num_users, num_items)\n",
    "vf = np.vectorize(lambda x: 1 if x >= 4 else 0)\n",
    "itemPopularity = np.zeros((num_items))\n",
    "for item in range(num_items):\n",
    "    numOfUsersRated = len(User_Item_Matix[:, item].nonzero()[0])\n",
    "    numOfUsersLiked = len(vf(User_Item_Matix[:, item]).nonzero()[0])\n",
    "    if numOfUsersRated == 0:\n",
    "        itemPopularity[item] = 0\n",
    "    else:\n",
    "        itemPopularity[item] = numOfUsersLiked/numOfUsersRated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Cth54RzXSCMD",
    "outputId": "6cfce2f1-2fb0-4dd7-ca80-4295fa8a6b04"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.24489796, 0.24561404, 0.24626866])"
      ]
     },
     "execution_count": 65,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_popularity = itemPopularity[np.argsort(itemPopularity)][490:493]\n",
    "sorted_popularity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZPbZudhSN-87",
    "outputId": "93563d0b-c3cd-4df0-9ad1-46913808a30d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "823     Great White Hype, The (1996)\n",
       "826                  Daylight (1996)\n",
       "1046             Multiplicity (1996)\n",
       "Name: movieTitle, dtype: object"
      ]
     },
     "execution_count": 66,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Movie_Name = moviesDF['movieTitle'][np.argsort(itemPopularity)][490:493]\n",
    "Movie_Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "E45pN2DsXQHL"
   },
   "outputs": [],
   "source": [
    "Item_similarity_matrix = 1 - pairwise_distances(User_Item_Matix.T, metric='cosine')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 433
    },
    "id": "3LgwVzZ5XrKu",
    "outputId": "31fb9575-8ec8-4b38-bd8e-870cca97c7e1"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>movieTitle</th>\n",
       "      <th>Toy Story (1995)</th>\n",
       "      <th>GoldenEye (1995)</th>\n",
       "      <th>Four Rooms (1995)</th>\n",
       "      <th>Get Shorty (1995)</th>\n",
       "      <th>Copycat (1995)</th>\n",
       "      <th>Shanghai Triad (Yao a yao yao dao waipo qiao) (1995)</th>\n",
       "      <th>Twelve Monkeys (1995)</th>\n",
       "      <th>Babe (1995)</th>\n",
       "      <th>Dead Man Walking (1995)</th>\n",
       "      <th>Richard III (1995)</th>\n",
       "      <th>Seven (Se7en) (1995)</th>\n",
       "      <th>Usual Suspects, The (1995)</th>\n",
       "      <th>Mighty Aphrodite (1995)</th>\n",
       "      <th>Postino, Il (1994)</th>\n",
       "      <th>Mr. Holland's Opus (1995)</th>\n",
       "      <th>French Twist (Gazon maudit) (1995)</th>\n",
       "      <th>From Dusk Till Dawn (1996)</th>\n",
       "      <th>White Balloon, The (1995)</th>\n",
       "      <th>Antonia's Line (1995)</th>\n",
       "      <th>Angels and Insects (1995)</th>\n",
       "      <th>Muppet Treasure Island (1996)</th>\n",
       "      <th>Braveheart (1995)</th>\n",
       "      <th>Taxi Driver (1976)</th>\n",
       "      <th>Rumble in the Bronx (1995)</th>\n",
       "      <th>Birdcage, The (1996)</th>\n",
       "      <th>Brothers McMullen, The (1995)</th>\n",
       "      <th>Bad Boys (1995)</th>\n",
       "      <th>Apollo 13 (1995)</th>\n",
       "      <th>Batman Forever (1995)</th>\n",
       "      <th>Belle de jour (1967)</th>\n",
       "      <th>Crimson Tide (1995)</th>\n",
       "      <th>Crumb (1994)</th>\n",
       "      <th>Desperado (1995)</th>\n",
       "      <th>Doom Generation, The (1995)</th>\n",
       "      <th>Free Willy 2: The Adventure Home (1995)</th>\n",
       "      <th>Mad Love (1995)</th>\n",
       "      <th>Nadja (1994)</th>\n",
       "      <th>Net, The (1995)</th>\n",
       "      <th>Strange Days (1995)</th>\n",
       "      <th>To Wong Foo, Thanks for Everything! Julie Newmar (1995)</th>\n",
       "      <th>...</th>\n",
       "      <th>Angel Baby (1995)</th>\n",
       "      <th>Sudden Manhattan (1996)</th>\n",
       "      <th>Butcher Boy, The (1998)</th>\n",
       "      <th>Men With Guns (1997)</th>\n",
       "      <th>Hana-bi (1997)</th>\n",
       "      <th>Niagara, Niagara (1997)</th>\n",
       "      <th>Big One, The (1997)</th>\n",
       "      <th>Butcher Boy, The (1998)</th>\n",
       "      <th>Spanish Prisoner, The (1997)</th>\n",
       "      <th>Temptress Moon (Feng Yue) (1996)</th>\n",
       "      <th>Entertaining Angels: The Dorothy Day Story (1996)</th>\n",
       "      <th>Chairman of the Board (1998)</th>\n",
       "      <th>Favor, The (1994)</th>\n",
       "      <th>Little City (1998)</th>\n",
       "      <th>Target (1995)</th>\n",
       "      <th>Substance of Fire, The (1996)</th>\n",
       "      <th>Getting Away With Murder (1996)</th>\n",
       "      <th>Small Faces (1995)</th>\n",
       "      <th>New Age, The (1994)</th>\n",
       "      <th>Rough Magic (1995)</th>\n",
       "      <th>Nothing Personal (1995)</th>\n",
       "      <th>8 Heads in a Duffel Bag (1997)</th>\n",
       "      <th>Brother's Kiss, A (1997)</th>\n",
       "      <th>Ripe (1996)</th>\n",
       "      <th>Next Step, The (1995)</th>\n",
       "      <th>Wedding Bell Blues (1996)</th>\n",
       "      <th>MURDER and murder (1996)</th>\n",
       "      <th>Tainted (1998)</th>\n",
       "      <th>Further Gesture, A (1996)</th>\n",
       "      <th>Kika (1993)</th>\n",
       "      <th>Mirage (1995)</th>\n",
       "      <th>Mamma Roma (1962)</th>\n",
       "      <th>Sunchaser, The (1996)</th>\n",
       "      <th>War at Home, The (1996)</th>\n",
       "      <th>Sweet Nothing (1995)</th>\n",
       "      <th>Mat' i syn (1997)</th>\n",
       "      <th>B. Monkey (1998)</th>\n",
       "      <th>Sliding Doors (1998)</th>\n",
       "      <th>You So Crazy (1994)</th>\n",
       "      <th>Scream of Stone (Schrei aus Stein) (1991)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Toy Story (1995)</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.402382</td>\n",
       "      <td>0.330245</td>\n",
       "      <td>0.454938</td>\n",
       "      <td>0.286714</td>\n",
       "      <td>0.116344</td>\n",
       "      <td>0.620979</td>\n",
       "      <td>0.481114</td>\n",
       "      <td>0.496288</td>\n",
       "      <td>0.273935</td>\n",
       "      <td>0.468291</td>\n",
       "      <td>0.460392</td>\n",
       "      <td>0.417509</td>\n",
       "      <td>0.347678</td>\n",
       "      <td>0.574377</td>\n",
       "      <td>0.224120</td>\n",
       "      <td>0.273916</td>\n",
       "      <td>0.046232</td>\n",
       "      <td>0.191772</td>\n",
       "      <td>0.232930</td>\n",
       "      <td>0.339196</td>\n",
       "      <td>0.527169</td>\n",
       "      <td>0.338105</td>\n",
       "      <td>0.467598</td>\n",
       "      <td>0.567950</td>\n",
       "      <td>0.227295</td>\n",
       "      <td>0.208472</td>\n",
       "      <td>0.592877</td>\n",
       "      <td>0.361657</td>\n",
       "      <td>0.150959</td>\n",
       "      <td>0.439441</td>\n",
       "      <td>0.259257</td>\n",
       "      <td>0.288536</td>\n",
       "      <td>0.090654</td>\n",
       "      <td>0.136757</td>\n",
       "      <td>0.108560</td>\n",
       "      <td>0.069805</td>\n",
       "      <td>0.368420</td>\n",
       "      <td>0.278386</td>\n",
       "      <td>0.246123</td>\n",
       "      <td>...</td>\n",
       "      <td>0.065390</td>\n",
       "      <td>0.010550</td>\n",
       "      <td>0.023592</td>\n",
       "      <td>0.014155</td>\n",
       "      <td>0.023592</td>\n",
       "      <td>0.023592</td>\n",
       "      <td>0.023592</td>\n",
       "      <td>0.023592</td>\n",
       "      <td>0.023592</td>\n",
       "      <td>0.014226</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.058979</td>\n",
       "      <td>0.047183</td>\n",
       "      <td>0.032856</td>\n",
       "      <td>0.035387</td>\n",
       "      <td>0.048189</td>\n",
       "      <td>0.058979</td>\n",
       "      <td>0.058979</td>\n",
       "      <td>0.035387</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.067404</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.033363</td>\n",
       "      <td>0.035387</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.035387</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.047183</td>\n",
       "      <td>0.047183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GoldenEye (1995)</th>\n",
       "      <td>0.402382</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.273069</td>\n",
       "      <td>0.502571</td>\n",
       "      <td>0.318836</td>\n",
       "      <td>0.083563</td>\n",
       "      <td>0.383403</td>\n",
       "      <td>0.337002</td>\n",
       "      <td>0.255252</td>\n",
       "      <td>0.171082</td>\n",
       "      <td>0.468506</td>\n",
       "      <td>0.459946</td>\n",
       "      <td>0.213972</td>\n",
       "      <td>0.125463</td>\n",
       "      <td>0.253162</td>\n",
       "      <td>0.098185</td>\n",
       "      <td>0.390438</td>\n",
       "      <td>0.113063</td>\n",
       "      <td>0.030692</td>\n",
       "      <td>0.091550</td>\n",
       "      <td>0.319308</td>\n",
       "      <td>0.483349</td>\n",
       "      <td>0.278182</td>\n",
       "      <td>0.434907</td>\n",
       "      <td>0.306639</td>\n",
       "      <td>0.206481</td>\n",
       "      <td>0.408737</td>\n",
       "      <td>0.483077</td>\n",
       "      <td>0.581119</td>\n",
       "      <td>0.089355</td>\n",
       "      <td>0.462797</td>\n",
       "      <td>0.160738</td>\n",
       "      <td>0.479187</td>\n",
       "      <td>0.072342</td>\n",
       "      <td>0.087347</td>\n",
       "      <td>0.215247</td>\n",
       "      <td>0.184592</td>\n",
       "      <td>0.562970</td>\n",
       "      <td>0.334570</td>\n",
       "      <td>0.256668</td>\n",
       "      <td>...</td>\n",
       "      <td>0.049324</td>\n",
       "      <td>0.035017</td>\n",
       "      <td>0.078299</td>\n",
       "      <td>0.046980</td>\n",
       "      <td>0.078299</td>\n",
       "      <td>0.078299</td>\n",
       "      <td>0.078299</td>\n",
       "      <td>0.078299</td>\n",
       "      <td>0.078299</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.078299</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.104399</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.104399</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.074571</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.055366</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.078299</td>\n",
       "      <td>0.078299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Four Rooms (1995)</th>\n",
       "      <td>0.330245</td>\n",
       "      <td>0.273069</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.324866</td>\n",
       "      <td>0.212957</td>\n",
       "      <td>0.106722</td>\n",
       "      <td>0.372921</td>\n",
       "      <td>0.200794</td>\n",
       "      <td>0.273669</td>\n",
       "      <td>0.158104</td>\n",
       "      <td>0.361165</td>\n",
       "      <td>0.319295</td>\n",
       "      <td>0.271402</td>\n",
       "      <td>0.190242</td>\n",
       "      <td>0.266335</td>\n",
       "      <td>0.167609</td>\n",
       "      <td>0.404239</td>\n",
       "      <td>0.126564</td>\n",
       "      <td>0.105377</td>\n",
       "      <td>0.187733</td>\n",
       "      <td>0.194546</td>\n",
       "      <td>0.293732</td>\n",
       "      <td>0.233814</td>\n",
       "      <td>0.381910</td>\n",
       "      <td>0.306447</td>\n",
       "      <td>0.214125</td>\n",
       "      <td>0.261303</td>\n",
       "      <td>0.269296</td>\n",
       "      <td>0.253074</td>\n",
       "      <td>0.126347</td>\n",
       "      <td>0.259129</td>\n",
       "      <td>0.185187</td>\n",
       "      <td>0.404930</td>\n",
       "      <td>0.179008</td>\n",
       "      <td>0.046315</td>\n",
       "      <td>0.073332</td>\n",
       "      <td>0.051270</td>\n",
       "      <td>0.240534</td>\n",
       "      <td>0.277311</td>\n",
       "      <td>0.176729</td>\n",
       "      <td>...</td>\n",
       "      <td>0.036615</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009736</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.096875</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.064583</td>\n",
       "      <td>0.064583</td>\n",
       "      <td>0.096875</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.018452</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.032292</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.096875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Get Shorty (1995)</th>\n",
       "      <td>0.454938</td>\n",
       "      <td>0.502571</td>\n",
       "      <td>0.324866</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.334239</td>\n",
       "      <td>0.090308</td>\n",
       "      <td>0.489283</td>\n",
       "      <td>0.490236</td>\n",
       "      <td>0.419044</td>\n",
       "      <td>0.252561</td>\n",
       "      <td>0.588337</td>\n",
       "      <td>0.584884</td>\n",
       "      <td>0.397251</td>\n",
       "      <td>0.266764</td>\n",
       "      <td>0.330457</td>\n",
       "      <td>0.169240</td>\n",
       "      <td>0.404889</td>\n",
       "      <td>0.100856</td>\n",
       "      <td>0.129363</td>\n",
       "      <td>0.208262</td>\n",
       "      <td>0.256467</td>\n",
       "      <td>0.572811</td>\n",
       "      <td>0.446568</td>\n",
       "      <td>0.413422</td>\n",
       "      <td>0.422300</td>\n",
       "      <td>0.380248</td>\n",
       "      <td>0.370192</td>\n",
       "      <td>0.531380</td>\n",
       "      <td>0.429785</td>\n",
       "      <td>0.216894</td>\n",
       "      <td>0.480685</td>\n",
       "      <td>0.351676</td>\n",
       "      <td>0.467377</td>\n",
       "      <td>0.127933</td>\n",
       "      <td>0.062932</td>\n",
       "      <td>0.170815</td>\n",
       "      <td>0.143852</td>\n",
       "      <td>0.457528</td>\n",
       "      <td>0.456760</td>\n",
       "      <td>0.331256</td>\n",
       "      <td>...</td>\n",
       "      <td>0.023691</td>\n",
       "      <td>0.016819</td>\n",
       "      <td>0.037609</td>\n",
       "      <td>0.022565</td>\n",
       "      <td>0.037609</td>\n",
       "      <td>0.037609</td>\n",
       "      <td>0.037609</td>\n",
       "      <td>0.037609</td>\n",
       "      <td>0.037609</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.056413</td>\n",
       "      <td>0.069838</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.075218</td>\n",
       "      <td>0.075218</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.064472</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.039890</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.094022</td>\n",
       "      <td>0.094022</td>\n",
       "      <td>0.037609</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.056413</td>\n",
       "      <td>0.075218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Copycat (1995)</th>\n",
       "      <td>0.286714</td>\n",
       "      <td>0.318836</td>\n",
       "      <td>0.212957</td>\n",
       "      <td>0.334239</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.037299</td>\n",
       "      <td>0.334769</td>\n",
       "      <td>0.259161</td>\n",
       "      <td>0.272448</td>\n",
       "      <td>0.055453</td>\n",
       "      <td>0.375809</td>\n",
       "      <td>0.373824</td>\n",
       "      <td>0.196495</td>\n",
       "      <td>0.103288</td>\n",
       "      <td>0.265123</td>\n",
       "      <td>0.112156</td>\n",
       "      <td>0.389191</td>\n",
       "      <td>0.077737</td>\n",
       "      <td>0.088631</td>\n",
       "      <td>0.061197</td>\n",
       "      <td>0.192679</td>\n",
       "      <td>0.319438</td>\n",
       "      <td>0.245088</td>\n",
       "      <td>0.237436</td>\n",
       "      <td>0.284242</td>\n",
       "      <td>0.228855</td>\n",
       "      <td>0.242739</td>\n",
       "      <td>0.326892</td>\n",
       "      <td>0.321288</td>\n",
       "      <td>0.127992</td>\n",
       "      <td>0.338714</td>\n",
       "      <td>0.151706</td>\n",
       "      <td>0.280778</td>\n",
       "      <td>0.110782</td>\n",
       "      <td>0.041288</td>\n",
       "      <td>0.213947</td>\n",
       "      <td>0.058926</td>\n",
       "      <td>0.391974</td>\n",
       "      <td>0.287402</td>\n",
       "      <td>0.272573</td>\n",
       "      <td>...</td>\n",
       "      <td>0.039565</td>\n",
       "      <td>0.028088</td>\n",
       "      <td>0.062807</td>\n",
       "      <td>0.037684</td>\n",
       "      <td>0.062807</td>\n",
       "      <td>0.062807</td>\n",
       "      <td>0.062807</td>\n",
       "      <td>0.062807</td>\n",
       "      <td>0.062807</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.094211</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.094211</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.053835</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.094211</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  1682 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "movieTitle         Toy Story (1995)  ...  Scream of Stone (Schrei aus Stein) (1991)\n",
       "Toy Story (1995)           1.000000  ...                                   0.047183\n",
       "GoldenEye (1995)           0.402382  ...                                   0.078299\n",
       "Four Rooms (1995)          0.330245  ...                                   0.096875\n",
       "Get Shorty (1995)          0.454938  ...                                   0.075218\n",
       "Copycat (1995)             0.286714  ...                                   0.094211\n",
       "\n",
       "[5 rows x 1682 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity_df = pd.DataFrame(data=Item_similarity_matrix, columns=moviesDF.movieTitle,index=moviesDF.movieTitle.values)\n",
    "similarity_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mHFYH5RRbaB_",
    "outputId": "130e6310-3829-4bf0-d284-c2c3a291bca2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------\n",
      "Top 5 most similar movies to Great White Hype, The (1996)\n",
      "\n",
      "720                                       Mallrats (1995)\n",
      "1058    Don't Be a Menace to South Central While Drink...\n",
      "819                                      Space Jam (1996)\n",
      "409                                        Kingpin (1996)\n",
      "26                                        Bad Boys (1995)\n",
      "----------------------------------------------------------\n",
      "Top 5 most similar movies to Daylight (1996)\n",
      "\n",
      "684          Executive Decision (1996)\n",
      "596                      Eraser (1996)\n",
      "404         Mission: Impossible (1996)\n",
      "146    Long Kiss Goodnight, The (1996)\n",
      "120      Independence Day (ID4) (1996)\n",
      "----------------------------------------------------------\n",
      "Top 5 most similar movies to Multiplicity (1996)\n",
      "\n",
      "404       Mission: Impossible (1996)\n",
      "120    Independence Day (ID4) (1996)\n",
      "741                    Ransom (1996)\n",
      "545              Broken Arrow (1996)\n",
      "596                    Eraser (1996)\n",
      "----------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print('----------------------------------------------------------')\n",
    "for movie in Movie_Name:\n",
    "    print('Top 5 most similar movies to {}'.format(movie))\n",
    "    print('')\n",
    "    print(moviesDF['movieTitle'][np.argsort(similarity_df[movie].tolist())[::-1]][1:6].to_string())\n",
    "    print('----------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jnRDOuH4zdvF"
   },
   "source": [
    "### (b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WYgg8GOa-mE5"
   },
   "source": [
    "I choose Great White Hype, The (1996),Daylight (1996), Multiplicity (1996) which have the popularity score of around 0.24, meaning they are not so popular. Since we are using item-item cosine similarity just based on the ratings, which are rated by the users subjectively, the factors leading to the similarity may include movie type, director/actors/actress, production areas, movie description etc and the cosine similarity cannot capture these implicit factors. Also the not-so-popular movies may have a sparse item vector, which do not provide a lot of information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QiSiG2UrzdvK"
   },
   "source": [
    "## Q7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sH63iq22zdvK"
   },
   "source": [
    "### (a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "NeUK2ZR5zdvM"
   },
   "outputs": [],
   "source": [
    "temp_matrix = np.zeros(User_Item_Matix.shape)\n",
    "temp_matrix[User_Item_Matix.nonzero()] = 1\n",
    "user_ratings = np.sum(temp_matrix, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 350
    },
    "id": "Fj3i6cQdtOwY",
    "outputId": "03bfbef1-85b5-4df4-9a2c-89f7edbca9d0"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.hist(user_ratings, bins='auto', rwidth=0.85)\n",
    "plt.ylabel('Number of People')\n",
    "plt.xlabel('Number of Movies Rated')\n",
    "plt.title('Histogram of Number of Ratings Per User')\n",
    "plt.grid(axis='y')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "aFPKCmmn2Lem"
   },
   "outputs": [],
   "source": [
    "#Choose tau = 200\n",
    "More_rating_num = len(np.argwhere(user_ratings > 200))\n",
    "Few_rating_num = len(np.argwhere(user_ratings <= 200))\n",
    "More_rating_indices = np.argwhere(user_ratings > 200).reshape(More_rating_num)\n",
    "Few_rating_indices = np.argwhere(user_ratings <= 200).reshape(Few_rating_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "6NLClcEi4Kro"
   },
   "outputs": [],
   "source": [
    "More_rating_df = rating_df[rating_df['userID'].isin(More_rating_indices)]\n",
    "Few_rating_df = rating_df[rating_df['userID'].isin(Few_rating_indices)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Rqg0okSg-loE",
    "outputId": "668870d5-6d07-4079-b467-89de3a611ffa"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:89: RuntimeWarning: invalid value encountered in true_divide\n",
      "16734it [00:05, 3285.27it/s]\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:110: RuntimeWarning: invalid value encountered in true_divide\n",
      "16734it [00:04, 3377.99it/s]\n"
     ]
    }
   ],
   "source": [
    "#More rating users (tau > 200)\n",
    "user_cosine_recsys = SimBasedRecSys('user','cosine')\n",
    "user_cosine_recsys.predict_all(More_rating_df, num_users, num_items)\n",
    "UU_More = user_cosine_recsys.evaluate_test(More_rating_df, copy=True)\n",
    "\n",
    "item_cosine_recsys = SimBasedRecSys('item','cosine')\n",
    "item_cosine_recsys.predict_all(More_rating_df, num_users, num_items)\n",
    "II_More = item_cosine_recsys.evaluate_test(More_rating_df, copy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yDdlhfN1lw-d",
    "outputId": "ce4ad913-9529-48af-bc41-25d6f661d3ea"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:89: RuntimeWarning: invalid value encountered in true_divide\n",
      "83098it [00:53, 1542.63it/s]\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:110: RuntimeWarning: invalid value encountered in true_divide\n",
      "83098it [00:53, 1560.14it/s]\n"
     ]
    }
   ],
   "source": [
    "#Few rating users (tau <= 200)\n",
    "user_cosine_recsys = SimBasedRecSys('user','cosine')\n",
    "user_cosine_recsys.predict_all(Few_rating_df, num_users, num_items)\n",
    "UU_Few = user_cosine_recsys.evaluate_test(Few_rating_df, copy=True)\n",
    "\n",
    "item_cosine_recsys = SimBasedRecSys('item','cosine')\n",
    "item_cosine_recsys.predict_all(Few_rating_df, num_users, num_items)\n",
    "II_Few = item_cosine_recsys.evaluate_test(Few_rating_df, copy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BVAFoA9lm2YA",
    "outputId": "3d906269-50ab-49cb-ef91-f04fccde672d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------RMSE----------\n",
      "More-User&User: 0.856974\n",
      "More-Item&Item: 0.997502\n",
      "Few-User&User: 0.946119\n",
      "Few-Item&Item: 0.971777\n"
     ]
    }
   ],
   "source": [
    "df_list = [UU_More, II_More, UU_Few, II_Few]\n",
    "case = ['More-User&User:', 'More-Item&Item:', 'Few-User&User:', 'Few-Item&Item:']\n",
    "print('----------RMSE----------')\n",
    "for i, df in enumerate(df_list):\n",
    "    RMSE = sqrt(mean_squared_error(df.iloc[:,2], df.iloc[:,4]))\n",
    "    print(case[i], round(RMSE,6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vIoLkvpjDj3w"
   },
   "source": [
    "*  I choose tau = 200 as a threshold.\n",
    "*  For user-user collaborative filtering, 'above the threshold' case performs better with lower RMSE, since these users rated more movies which give less sparse vectors with more information to compute the user similarity.\n",
    "*  For item-item collaborative filtering, 'below the threshold' case performs better with lower RMSE,\n",
    "since there are more users in this group, giving higher probability of higher number of ratings for each item, which potentially provides more information to compute the item similarity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fjEBSNwkY8uT"
   },
   "source": [
    "## Q8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {
    "id": "g8_QUmdSY_Im"
   },
   "outputs": [],
   "source": [
    "class CompetitionRecSys(object):\n",
    "    \"\"\"\n",
    "    You can define new methods if you need. Don't use global variables in the class. \n",
    "    \"\"\"\n",
    "    def __init__(self, num_feat=70, epsilon=0.5, _lambda=0.3, momentum=0.99, maxepoch=20, num_batches=100, batch_size=1000):\n",
    "        \"\"\"\n",
    "        Initialization of the class\n",
    "        1. Make sure to fill out self.pred_column_name, the name you give  to your competition method\n",
    "        \n",
    "        \"\"\"\n",
    "        ########## your code goes here ###########\n",
    "        self.num_feat = num_feat  # Number of latent features,\n",
    "        self.epsilon = epsilon  # learning rate,\n",
    "        self._lambda = _lambda  # L2 regularization,\n",
    "        self.momentum = momentum  # momentum of the gradient,\n",
    "        self.maxepoch = maxepoch  # Number of epoch before stop,\n",
    "        self.num_batches = num_batches  # Number of batches in each epoch (for SGD optimization),\n",
    "        self.batch_size = batch_size  # Number of training samples used in each batches (for SGD optimization)\n",
    "        self.test = False\n",
    "        self.w_Item = None  # Item feature vectors\n",
    "        self.w_User = None  # User feature vectors\n",
    "        \n",
    "        self.rmse_train = []\n",
    "        self.rmse_test = []\n",
    "        self.pred_column_name = 'PMF_adjusted'\n",
    "        ###########         end         ###########\n",
    "\n",
    "    def predict_all(self, train_vec, num_user, num_item):\n",
    "        \"\"\"\n",
    "        INPUT: \n",
    "            data: pandas DataFrame. columns=['userID', 'itemID', 'rating'...]\n",
    "            num_user: scalar. number of users\n",
    "            num_item: scalar. number of items\n",
    "        OUTPUT:\n",
    "            no return... \n",
    "        \n",
    "        NOTES:\n",
    "            This function is where you train your model\n",
    "        \"\"\"\n",
    "                \n",
    "        ########## your code goes here ###########\n",
    "        train_vec = train_vec.iloc[:, :3].values #get the 10000x3 matrix,\n",
    "        if self.test:\n",
    "          train_vec, val_vec = train_test_split(train_vec) #default test set size\n",
    "          pairs_val = val_vec.shape[0] #number of records in test set\n",
    "          self.mean_rating_test = np.mean(val_vec[:, 2])  #avg rating for test set\n",
    "        self.mean_rating_train = np.mean(train_vec[:, 2])  # avg rating for train set\n",
    "        pairs_train = train_vec.shape[0]  # num of records in tain set\n",
    "        \n",
    "\n",
    "        # to avoid out of bound\n",
    "        num_user += 1  \n",
    "        num_item += 1  \n",
    "        # initialize\n",
    "        self.epoch = 0\n",
    "        \n",
    "        ########### your code goes here ###########\n",
    "    \n",
    "        self.w_Item = sqrt(0.1) * np.random.randn(num_item, self.num_feat)  # item M x D(latent feature) \n",
    "        self.w_User = sqrt(0.1) * np.random.randn(num_user, self.num_feat)  # user N x D(latent feature) \n",
    "    \n",
    "    \n",
    "        ###########         end         ###########  \n",
    "\n",
    "        self.w_Item_inc = np.zeros((num_item, self.num_feat))  # accumulate the gradient\n",
    "        self.w_User_inc = np.zeros((num_user, self.num_feat))  # accumulate the gradient\n",
    "        while self.epoch < self.maxepoch: \n",
    "            self.epoch += 1\n",
    "\n",
    "            # Shuffle training truples\n",
    "            shuffled_order = np.arange(train_vec.shape[0])  \n",
    "            np.random.shuffle(shuffled_order)  #shuffle the above order every time\n",
    "\n",
    "            # Batch update\n",
    "            for batch in range(self.num_batches): \n",
    "                # print \"epoch %d batch %d\" % (self.epoch, batch+1)\n",
    "\n",
    "                test = np.arange(self.batch_size * batch, self.batch_size * (batch + 1)) # get each batch\n",
    "                batch_idx = np.mod(test, shuffled_order.shape[0])  # get the real data index\n",
    "\n",
    "\n",
    "                batch_UserID = np.array(train_vec[shuffled_order[batch_idx], 0], dtype='int32')\n",
    "                batch_ItemID = np.array(train_vec[shuffled_order[batch_idx], 1], dtype='int32')\n",
    "\n",
    "                # Compute Compute mean rating subtracted rating  \n",
    "                ########### your code goes here ###########\n",
    "            \n",
    "                pred_out = np.sum(np.multiply(self.w_User[batch_UserID, :], self.w_Item[batch_ItemID, :]), axis = 1) #size (batch_size, )\n",
    "            \n",
    "            \n",
    "                ###########         end         ########### \n",
    "\n",
    "                rawErr = pred_out + self.mean_rating_train - train_vec[shuffled_order[batch_idx], 2]\n",
    "\n",
    "                # Compute gradients\n",
    "                Ix_User = 2 * np.multiply(rawErr[:, np.newaxis], self.w_Item[batch_ItemID, :]) \\\n",
    "                       + self._lambda * self.w_User[batch_UserID, :]\n",
    "                Ix_Item = 2 * np.multiply(rawErr[:, np.newaxis], self.w_User[batch_UserID, :]) \\\n",
    "                       + self._lambda * (self.w_Item[batch_ItemID, :])  # np.newaxis :increase the dimension\n",
    "\n",
    "                dw_Item = np.zeros((num_item, self.num_feat))\n",
    "                dw_User = np.zeros((num_user, self.num_feat))\n",
    "\n",
    "                # loop to aggreate the gradients of the same element\n",
    "                for i in range(self.batch_size):\n",
    "                    dw_Item[batch_ItemID[i], :] += Ix_Item[i, :]\n",
    "                    dw_User[batch_UserID[i], :] += Ix_User[i, :]\n",
    "\n",
    "                # Update with momentum\n",
    "                self.w_Item_inc = self.momentum * self.w_Item_inc + self.epsilon * dw_Item / self.batch_size\n",
    "                self.w_User_inc = self.momentum * self.w_User_inc + self.epsilon * dw_User / self.batch_size\n",
    "\n",
    "                self.w_Item = self.w_Item - self.w_Item_inc\n",
    "                self.w_User = self.w_User - self.w_User_inc\n",
    "\n",
    "                # Compute Compute mean rating subtracted rating \n",
    "                if batch == self.num_batches - 1:\n",
    "                    train_user_idx = np.array(train_vec[:, 0], dtype='int32')\n",
    "                    train_item_idx = np.array(train_vec[:, 1], dtype='int32')\n",
    "                    ########### your code goes here ###########\n",
    "            \n",
    "                    pred_out = np.sum(np.multiply(self.w_User[train_user_idx, :], self.w_Item[train_item_idx, :]), axis = 1) # size(pairs_train, )\n",
    "            \n",
    "            \n",
    "                    ###########         end         ########### \n",
    "                    rawErr = pred_out + self.mean_rating_train - train_vec[:, 2] \n",
    "                    obj = np.linalg.norm(rawErr) ** 2 \\\n",
    "                          + 0.5 * self._lambda * (np.linalg.norm(self.w_User) ** 2 + np.linalg.norm(self.w_Item) ** 2)\n",
    "\n",
    "                    self.rmse_train.append(np.sqrt(obj / pairs_train))\n",
    "\n",
    "                # Compute validation error\n",
    "                if batch == self.num_batches - 1 and self.test:\n",
    "                    val_user_idx = np.array(val_vec[:, 0], dtype='int32')\n",
    "                    val_item_idx = np.array(val_vec[:, 1], dtype='int32')\n",
    "                    ########### your code goes here ###########\n",
    "            \n",
    "                    pred_out = np.sum(np.multiply(self.w_User[val_user_idx, :], self.w_Item[val_item_idx, :]), axis = 1) #size(pairs_val, )\n",
    "            \n",
    "            \n",
    "                    ###########         end         ########### \n",
    "                    rawErr = pred_out + self.mean_rating_test - val_vec[:, 2]\n",
    "                    self.rmse_test.append(np.linalg.norm(rawErr) / np.sqrt(pairs_val))\n",
    "        ###########         end         ###########\n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "    def evaluate_test(self, test_df, copy=False):\n",
    "        \"\"\"\n",
    "            INPUT:\n",
    "                data: pandas DataFrame. columns=['userID', 'itemID', 'rating'...]\n",
    "            OUTPUT:\n",
    "                predictions:  pandas DataFrame. \n",
    "                              columns=['userID', 'itemID', 'rating', 'base-method'...]\n",
    "\n",
    "            NOTES:\n",
    "            This function is where your model makes prediction \n",
    "            Please fill out: prediction.loc[index, self.pred_column_name] = None                            \n",
    "                              \n",
    "        \"\"\"\n",
    "        if copy:\n",
    "            prediction = pd.DataFrame(test_df.copy(), columns=['userID', 'itemID', 'rating'])\n",
    "        else:\n",
    "            prediction = pd.DataFrame(test_df, columns=['userID', 'itemID', 'rating'])\n",
    "        prediction[self.pred_column_name] = np.nan\n",
    "        \n",
    "        for (index, \n",
    "             userID, \n",
    "             itemID) in tqdm(prediction[['userID','itemID']].itertuples()):\n",
    "            ########### your code goes here ###########\n",
    "            prediction.loc[index, self.pred_column_name] = (np.dot(self.w_Item, self.w_User[int(userID), :]) + self.mean_rating_train)[int(itemID)]\n",
    "            ###########         end         ###########\n",
    "\n",
    "        return prediction\n",
    "          \n",
    "    def getPredColName(self):\n",
    "        \"\"\"\n",
    "            return prediction column name\n",
    "        \"\"\"\n",
    "        return self.pred_column_name\n",
    "    \n",
    "    def reset(self):\n",
    "        \"\"\"\n",
    "            reuse the instance of the class by removing model\n",
    "        \"\"\"\n",
    "        ########### your code goes here ###########\n",
    "        try:\n",
    "            self.w_Item = None \n",
    "            self.w_User = None\n",
    "        except:\n",
    "            print(\"You do not have model..\")\n",
    "\n",
    "    def set_params(self, parameters):\n",
    "        if isinstance(parameters, dict):\n",
    "            self.num_feat = parameters.get(\"num_feat\", 10)\n",
    "            self.epsilon = parameters.get(\"epsilon\", 1)\n",
    "            self._lambda = parameters.get(\"_lambda\", 0.1)\n",
    "            self.momentum = parameters.get(\"momentum\", 0.8)\n",
    "            self.maxepoch = parameters.get(\"maxepoch\", 20)\n",
    "            self.num_batches = parameters.get(\"num_batches\", 10)\n",
    "            self.batch_size = parameters.get(\"batch_size\", 1000)\n",
    "            self.test = parameters.get(\"test_mode\", False)\n",
    "        else:\n",
    "          raise Exception(\"You need to pass in a dictionary\")\n",
    "        ##########         end         ###########\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BzNDsLWUZAci",
    "outputId": "0aa51b18-6dcc-4162-eb84-96acb14c6c46"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing algorithm PMF_adjusted\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20000it [00:13, 1510.00it/s]\n",
      "20000it [00:12, 1543.31it/s]\n",
      "20000it [00:12, 1571.79it/s]\n",
      "20000it [00:12, 1569.21it/s]\n",
      "20000it [00:12, 1562.28it/s]\n"
     ]
    }
   ],
   "source": [
    "competition = CompetitionRecSys()\n",
    "algorithm_instances = [competition]\n",
    "cv_rp = CrossValidation('RPrecision')\n",
    "rp = cv_rp.run(algorithm_instances, num_users, num_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vedQIZN8ZAfb",
    "outputId": "d52f8ac1-f38e-473c-c40a-a0f68fe55c21"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'PMF_adjusted': [[0.7253015851772032,\n",
       "   0.7163200018830184,\n",
       "   0.7231795717386471,\n",
       "   0.7331658523416033,\n",
       "   0.7381972727603188],\n",
       "  0.7272328567801581,\n",
       "  0.7165757156284993,\n",
       "  0.737889997931817]}"
      ]
     },
     "execution_count": 330,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZD9B8R1GvZNX"
   },
   "source": [
    "I just did hyperparameter tuning for the PMF model. I changed the momentum, epsilon, lambda and number of featues.\n",
    "*  The momentum acts as a damping factor, which damps the oscillations.\n",
    "*  Epsilon is the learning rate, changed it to 0.5 for slower convergence.\n",
    "*  Lambda is regularization, increased it a bit to give more penalty.\n",
    "*  Increased the number of featues to get better relationship for the latent variables and the prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "id": "G2V2BXb-zdvQ"
   },
   "source": [
    "# Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "id": "sjWEiRzezdvR"
   },
   "outputs": [],
   "source": [
    "# Constants for validation only\n",
    "ROW_NUM = 943\n",
    "COL_NUM = 1682\n",
    "RATING_COL = 'rating'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mqZ3DOSHzdvV"
   },
   "source": [
    "### dataPreprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "id": "A4jypcIRzdvY"
   },
   "outputs": [],
   "source": [
    "def validateDataPreprocessor(path=MOVIELENS_DIR, getData=getData, getMatrix=CrossValidation.getMatrix):\n",
    "    validation_df = getData(MOVIELENS_DIR, 'u1.test')\n",
    "    try:\n",
    "        matrix = getMatrix(validation_df, ROW_NUM, COL_NUM, RATING_COL)\n",
    "    except:\n",
    "        print('dataPreprocessor function has error')\n",
    "        return\n",
    "    try:\n",
    "        assert(matrix.shape == (ROW_NUM,COL_NUM)),\\\n",
    "        \"Shape of matrix{0} doesn't match predefined shape (943,1682)\".format(matrix.shape)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "    return validation_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "id": "G_Tc_IVazdvd"
   },
   "outputs": [],
   "source": [
    "validation_df = validateDataPreprocessor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4_PmoIrWzdvf"
   },
   "source": [
    "## Baseline Recommendation Systems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zGA1yZ9hzdvf"
   },
   "source": [
    "### Popularity Based Recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "id": "O_ySapEazdvg"
   },
   "outputs": [],
   "source": [
    "def validatePopularityRecSys(validation_df=validation_df, BaseLineRecSys = BaseLineRecSys):\n",
    "    popularity_recsys = BaseLineRecSys('popularity')\n",
    "    try:\n",
    "        popularity_recsys.predict_all(validation_df, ROW_NUM, COL_NUM)\n",
    "    except Exception as e:        \n",
    "        print('popularity function has error')\n",
    "        print(e)\n",
    "        return\n",
    "    try:\n",
    "        predictionMatrix = popularity_recsys.getModel()\n",
    "        assert(predictionMatrix.shape == (ROW_NUM, COL_NUM)),\\\n",
    "        \"Shape of matrix{0} doesn't match predefined shape ({1},{2})\"\\\n",
    "        .format(predictionMatrix.shape,ROW_NUM, COL_NUM)\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "id": "TyCJ1Be0zdvi"
   },
   "outputs": [],
   "source": [
    "validatePopularityRecSys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4g1wwQpxzdvp"
   },
   "source": [
    "### User Average Based Recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "id": "K1KASm63zdvp"
   },
   "outputs": [],
   "source": [
    "def validateUserAverRecSys(validation_df=validation_df, BaseLineRecSys = BaseLineRecSys):\n",
    "    useraverage_recsys = BaseLineRecSys('useraverage')\n",
    "    try:\n",
    "        useraverage_recsys.predict_all(validation_df, ROW_NUM, COL_NUM)\n",
    "    except:\n",
    "        print('useraverage function has error')\n",
    "        return\n",
    "    try:\n",
    "        predictionMatrix = useraverage_recsys.getModel()\n",
    "        assert(predictionMatrix.shape == (ROW_NUM, COL_NUM)),\\\n",
    "        \"Shape of matrix{0} doesn't match predefined shape ({1},{2})\"\\\n",
    "        .format(predictionMatrix.shape,ROW_NUM, COL_NUM)\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "id": "5A36VedIzdvs"
   },
   "outputs": [],
   "source": [
    "validateUserAverRecSys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vlxJxooBzdvx"
   },
   "source": [
    "## Similary Based Recommendation Systems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cvmIFAXXzdvy"
   },
   "source": [
    "### Euclidean Similarity Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "id": "z74E1PMRzdvy"
   },
   "outputs": [],
   "source": [
    "def validateEuclidean(validation_df=validation_df, getMatrix=CrossValidation.getMatrix):\n",
    "    matrix = getMatrix(validation_df, ROW_NUM, COL_NUM, RATING_COL)\n",
    "    try:\n",
    "        sim_matrix = SimBasedRecSys.euclidean(matrix)\n",
    "        assert(sim_matrix.shape == (ROW_NUM, ROW_NUM)),\\\n",
    "        \"Shape of matrix{0} doesn't match predefined shape ({1},{2})\"\\\n",
    "        .format(sim_matrix.shape,ROW_NUM,ROW_NUM)\n",
    "        assert(np.any(sim_matrix <= 1)),\\\n",
    "               \"Exist similarity value that is not less or equal to 1.\"\n",
    "    except Exception as e:\n",
    "        print(e)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "id": "qqzEUppEzdv4"
   },
   "outputs": [],
   "source": [
    "validateEuclidean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UnBQxFEPzdv6"
   },
   "source": [
    "### Customized Similarity Function (test somethingelse function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "id": "mPpRR_hjzdv6"
   },
   "outputs": [],
   "source": [
    "def validateCustomizedSim(validation_df=validation_df, getMatrix=CrossValidation.getMatrix):\n",
    "    matrix = getMatrix(validation_df, ROW_NUM, COL_NUM, RATING_COL)\n",
    "    try:\n",
    "        sim_matrix = SimBasedRecSys.somethingelse(matrix)\n",
    "        assert(sim_matrix.shape == (ROW_NUM, ROW_NUM)),\\\n",
    "        \"Shape of matrix{0} doesn't match predefined shape ({1},{2})\"\\\n",
    "        .format(sim_matrix.shape,ROW_NUM,ROW_NUM)\n",
    "        assert(np.any(sim_matrix <= 1)),\\\n",
    "               \"Exist similarity value that is not less or equal to 1.\"\n",
    "    except Exception as e:\n",
    "        print(e) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "id": "4uGIWOS7zdv8"
   },
   "outputs": [],
   "source": [
    "validateCustomizedSim()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DMKOOB6mzdwB"
   },
   "source": [
    "### User-User Similarity Based Recommendation System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "id": "t_V0gdBTzdwB"
   },
   "outputs": [],
   "source": [
    "def validateUUSimBasedRecSys(validation_df=validation_df, dataPreprocessor=dataPreprocessor):\n",
    "    try:\n",
    "        user_cosine_recsys = SimBasedRecSys('user','cosine', dataPreprocessor)\n",
    "    except:\n",
    "        print(\"Got error when instantiate SimBasedRecSys\")\n",
    "        return\n",
    "    \n",
    "    try:\n",
    "        user_cosine_recsys.predict_all(validation_df, ROW_NUM, COL_NUM)\n",
    "        predictionMatrix = user_cosine_recsys.getModel()\n",
    "        assert(predictionMatrix.shape == (ROW_NUM, COL_NUM)),\\\n",
    "        \"Shape of matrix{0} doesn't match predefined shape ({1},{2})\"\\\n",
    "        .format(predictionMatrix.shape,ROW_NUM, COL_NUM)\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KkausxHizdwE",
    "outputId": "dc785970-fa1c-4cce-fa39-38df85f7ebf0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:89: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    }
   ],
   "source": [
    "validateUUSimBasedRecSys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1IAGUMvwzdwH"
   },
   "source": [
    "### Item-Item Similarity Based Recommendation System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "id": "H-j6pDB3zdwH"
   },
   "outputs": [],
   "source": [
    "def validateIISimBasedRecSys(validation_df=validation_df, dataPreprocessor=dataPreprocessor):\n",
    "    try:\n",
    "        item_cosine_recsys = SimBasedRecSys('item','cosine', dataPreprocessor)\n",
    "    except:\n",
    "        print(\"Got error when instantiate SimBasedRecSys\")\n",
    "        return\n",
    "    \n",
    "    try:\n",
    "        item_cosine_recsys.predict_all(validation_df, ROW_NUM, COL_NUM)\n",
    "        predictionMatrix = item_cosine_recsys.getModel()\n",
    "        assert(predictionMatrix.shape == (ROW_NUM, COL_NUM)),\\\n",
    "        \"Shape of matrix{0} doesn't match predefined shape ({1},{2})\"\\\n",
    "        .format(predictionMatrix.shape,ROW_NUM, COL_NUM)\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TjAlZnpYzdwK",
    "outputId": "0656ac6f-28d9-4138-cd91-42bb50ee2fbb"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:110: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    }
   ],
   "source": [
    "validateIISimBasedRecSys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FYo97yYTCKbI"
   },
   "source": [
    "### Probabilistic Matrix Factorization Recommendation System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "id": "rB1_H8mxzdwO"
   },
   "outputs": [],
   "source": [
    "def validatePMFRecSys(validation_df=validation_df):\n",
    "    try:\n",
    "        pmf = PMFRecSys()\n",
    "        pmf.set_params({\"num_feat\": 10, \"epsilon\": 1, \"_lambda\": 0.1, \"momentum\": 0.8, \"maxepoch\": 1, \"num_batches\": 100,\n",
    "                \"batch_size\": 1000, 'test_mode':True})\n",
    "        pmf.predict_all(rating_df, ROW_NUM, COL_NUM)\n",
    "    except:\n",
    "        print(\"Got error when instantiate PMFRecSys\")\n",
    "        return\n",
    "    \n",
    "    try:\n",
    "        pmf.predict_all(validation_df, ROW_NUM, COL_NUM)\n",
    "        W_item, W_user = pmf.w_Item, pmf.w_User\n",
    "        assert(W_item.shape == (COL_NUM+1, 10) and W_user.shape == (ROW_NUM+1, 10)),\\\n",
    "        \"Shape of w_Item and W_User doesn't match predefined shape\"\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "id": "BW82XMfdzdwQ"
   },
   "outputs": [],
   "source": [
    "validatePMFRecSys(validation_df=validation_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ldve7N_0DRF4"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "rs_assignment.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
